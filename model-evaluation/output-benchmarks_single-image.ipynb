{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc1875c5db14d1895c243480d21343c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing fake image:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark ID: pix2pix_boston_20241222_203730\n",
      "\n",
      "Metrics for single image:\n",
      "--------------------------------------------------\n",
      "polygon_count_ratio: 1.0000\n",
      "mean_area_ratio: 1.4528\n",
      "mean_iou: 0.3143\n",
      "mse: 0.0525\n",
      "psnr: 12.7975\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Imports and Core Evaluator Class\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "from skimage.metrics import (\n",
    "    mean_squared_error, \n",
    "    structural_similarity as ssim, \n",
    "    peak_signal_noise_ratio\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ParcelEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        min_area=50,\n",
    "        color_dist_threshold=30,\n",
    "        win_size_for_ssim=3,\n",
    "        save_visualizations=True\n",
    "    ):\n",
    "        \"\"\"Initialize the ParcelEvaluator with configuration parameters.\"\"\"\n",
    "        self.min_area = min_area\n",
    "        self.color_dist_threshold = color_dist_threshold\n",
    "        self.win_size_for_ssim = win_size_for_ssim\n",
    "        self.save_visualizations = save_visualizations\n",
    "\n",
    "    def create_benchmark_id(self, model_name=None):\n",
    "        \"\"\"Create a unique identifier for this benchmark run.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        if model_name:\n",
    "            return f\"{model_name}_{timestamp}\"\n",
    "        return f\"benchmark_{timestamp}\"\n",
    "\n",
    "    def setup_output_directory(self, base_dir, benchmark_id):\n",
    "        \"\"\"Create and setup output directory structure.\"\"\"\n",
    "        output_dir = Path(base_dir) / benchmark_id\n",
    "        \n",
    "        # Create subdirectories\n",
    "        (output_dir / \"visualizations\").mkdir(parents=True, exist_ok=True)\n",
    "        (output_dir / \"metrics\").mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        return output_dir\n",
    "\n",
    "    def save_config(self, output_dir):\n",
    "        \"\"\"Save evaluator configuration.\"\"\"\n",
    "        config = {\n",
    "            'min_area': self.min_area,\n",
    "            'color_dist_threshold': self.color_dist_threshold,\n",
    "            'win_size_for_ssim': self.win_size_for_ssim,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        with open(output_dir / \"metrics\" / \"config.json\", 'w') as f:\n",
    "            json.dump(config, f, indent=4)\n",
    "\n",
    "    def load_and_preprocess(self, image_path):\n",
    "        \"\"\"Load and preprocess image to RGB.\"\"\"\n",
    "        img_bgr = cv2.imread(str(image_path))\n",
    "        if img_bgr is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def parse_color_coded_image(self, image_rgb):\n",
    "        \"\"\"Extract exact color polygons from real image.\"\"\"\n",
    "        h, w = image_rgb.shape[:2]\n",
    "        color2mask = {}\n",
    "        image_rgb = image_rgb.astype(np.float32)\n",
    "\n",
    "        # Process image in chunks for memory efficiency\n",
    "        chunk_size = 100\n",
    "        for y_start in range(0, h, chunk_size):\n",
    "            y_end = min(y_start + chunk_size, h)\n",
    "            for x_start in range(0, w, chunk_size):\n",
    "                x_end = min(x_start + chunk_size, w)\n",
    "                chunk = image_rgb[y_start:y_end, x_start:x_end]\n",
    "                \n",
    "                for y in range(chunk.shape[0]):\n",
    "                    for x in range(chunk.shape[1]):\n",
    "                        c = tuple(chunk[y, x])\n",
    "                        if c not in color2mask:\n",
    "                            color2mask[c] = np.zeros((h, w), dtype=np.uint8)\n",
    "                        color2mask[c][y_start + y, x_start + x] = 1\n",
    "\n",
    "        return self._masks_to_polygons(color2mask)\n",
    "\n",
    "    def parse_fake_image(self, fake_rgb, target_colors):\n",
    "        \"\"\"Parse fake image using color threshold approach.\"\"\"\n",
    "        h, w = fake_rgb.shape[:2]\n",
    "        fake_rgb = fake_rgb.astype(np.float32)\n",
    "        color2mask = {tuple(float(x) for x in c): np.zeros((h, w), dtype=np.uint8) \n",
    "                     for c in target_colors}\n",
    "\n",
    "        # Process in chunks\n",
    "        chunk_size = 100\n",
    "        for y_start in tqdm(range(0, h, chunk_size), desc=\"Processing fake image\", leave=False):\n",
    "            y_end = min(y_start + chunk_size, h)\n",
    "            for x_start in range(0, w, chunk_size):\n",
    "                x_end = min(x_start + chunk_size, w)\n",
    "                chunk = fake_rgb[y_start:y_end, x_start:x_end]\n",
    "                \n",
    "                for y in range(chunk.shape[0]):\n",
    "                    for x in range(chunk.shape[1]):\n",
    "                        pixel = chunk[y, x]\n",
    "                        best_color = min(\n",
    "                            color2mask.keys(),\n",
    "                            key=lambda c: np.sqrt(np.sum((pixel - c) ** 2))\n",
    "                        )\n",
    "                        if np.sqrt(np.sum((pixel - best_color) ** 2)) < self.color_dist_threshold:\n",
    "                            color2mask[best_color][y_start + y, x_start + x] = 1\n",
    "\n",
    "        return self._masks_to_polygons(color2mask)\n",
    "\n",
    "    def _masks_to_polygons(self, color2mask):\n",
    "        \"\"\"Convert masks to merged polygons.\"\"\"\n",
    "        color2poly = {}\n",
    "        for color, mask in color2mask.items():\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            polys = []\n",
    "            for cnt in contours:\n",
    "                area = cv2.contourArea(cnt)\n",
    "                if area < self.min_area:\n",
    "                    continue\n",
    "                ep = 0.02 * cv2.arcLength(cnt, True)\n",
    "                approx = cv2.approxPolyDP(cnt, ep, True)\n",
    "                coords = np.squeeze(approx).reshape(-1, 2) if approx.size > 0 else np.array([])\n",
    "                if coords.size > 0:\n",
    "                    try:\n",
    "                        p = Polygon(coords)\n",
    "                        if p.is_valid and p.area >= self.min_area:\n",
    "                            polys.append(p)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    \n",
    "            if not polys:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                merged = unary_union(polys)\n",
    "                if merged.geom_type == 'MultiPolygon':\n",
    "                    big = max(merged.geoms, key=lambda g: g.area)\n",
    "                    color2poly[color] = big\n",
    "                else:\n",
    "                    color2poly[color] = merged\n",
    "            except Exception as e:\n",
    "                print(f\"Error merging polygons for color {color}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        return color2poly\n",
    "\n",
    "    def compute_geometric_metrics(self, real_polys, fake_polys):\n",
    "        \"\"\"Compute geometric comparison metrics.\"\"\"\n",
    "        metrics = {\n",
    "            'polygon_count_ratio': len(fake_polys) / len(real_polys) if real_polys else 0,\n",
    "            'area_ratios': [],\n",
    "            'iou_scores': []\n",
    "        }\n",
    "        \n",
    "        for color, real_poly in real_polys.items():\n",
    "            if color in fake_polys:\n",
    "                fake_poly = fake_polys[color]\n",
    "                # Area ratio\n",
    "                area_ratio = fake_poly.area / real_poly.area if real_poly.area > 0 else 0\n",
    "                metrics['area_ratios'].append(area_ratio)\n",
    "                \n",
    "                # IoU\n",
    "                try:\n",
    "                    intersection = real_poly.intersection(fake_poly).area\n",
    "                    union = real_poly.union(fake_poly).area\n",
    "                    iou = intersection / union if union > 0 else 0\n",
    "                    metrics['iou_scores'].append(iou)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "        metrics['mean_area_ratio'] = np.mean(metrics['area_ratios']) if metrics['area_ratios'] else 0\n",
    "        metrics['mean_iou'] = np.mean(metrics['iou_scores']) if metrics['iou_scores'] else 0\n",
    "        return metrics\n",
    "\n",
    "    def compute_image_metrics(self, real_rgb, fake_rgb):\n",
    "        \"\"\"Compute traditional image comparison metrics.\"\"\"\n",
    "        if real_rgb.shape != fake_rgb.shape:\n",
    "            return {'mse': float('inf'), 'psnr': 0, 'ssim': 0}\n",
    "            \n",
    "        real_f = real_rgb.astype(np.float32) / 255\n",
    "        fake_f = fake_rgb.astype(np.float32) / 255\n",
    "        \n",
    "        metrics = {\n",
    "            'mse': mean_squared_error(real_f, fake_f),\n",
    "            'psnr': peak_signal_noise_ratio(real_f, fake_f, data_range=1.0),\n",
    "            'ssim': ssim(real_f, fake_f, data_range=1.0, \n",
    "                        channel_axis=2, win_size=self.win_size_for_ssim)\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def visualize_comparison(self, real_rgb, fake_rgb, real_polys, fake_polys, output_path):\n",
    "        \"\"\"Create visualization of the comparison.\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # Plot fake image and its polygons\n",
    "        ax1.imshow(fake_rgb)\n",
    "        for poly in fake_polys.values():\n",
    "            if poly.is_valid:\n",
    "                x, y = poly.exterior.xy\n",
    "                ax1.plot(x, y, 'r-', linewidth=1)\n",
    "        ax1.set_title('Generated Image with Detected Parcels')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Plot real image and its polygons\n",
    "        ax2.imshow(real_rgb)\n",
    "        for poly in real_polys.values():\n",
    "            if poly.is_valid:\n",
    "                x, y = poly.exterior.xy\n",
    "                ax2.plot(x, y, 'g-', linewidth=1)\n",
    "        ax2.set_title('Ground Truth with Parcels')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def evaluate(self, real_path, fake_path, benchmark_dir=\"benchmark-outputs\", model_name=None):\n",
    "        \"\"\"Main evaluation function.\"\"\"\n",
    "        # Create benchmark ID and setup directories\n",
    "        benchmark_id = self.create_benchmark_id(model_name)\n",
    "        output_dir = self.setup_output_directory(benchmark_dir, benchmark_id)\n",
    "        \n",
    "        # Save configuration\n",
    "        self.save_config(output_dir)\n",
    "        \n",
    "        # Load images\n",
    "        real_rgb = self.load_and_preprocess(real_path)\n",
    "        fake_rgb = self.load_and_preprocess(fake_path)\n",
    "        \n",
    "        # Parse polygons\n",
    "        real_polys = self.parse_color_coded_image(real_rgb)\n",
    "        fake_polys = self.parse_fake_image(fake_rgb, list(real_polys.keys()))\n",
    "        \n",
    "        # Compute metrics\n",
    "        geometric_metrics = self.compute_geometric_metrics(real_polys, fake_polys)\n",
    "        image_metrics = self.compute_image_metrics(real_rgb, fake_rgb)\n",
    "        \n",
    "        # Combine metrics\n",
    "        all_metrics = {**geometric_metrics, **image_metrics}\n",
    "        \n",
    "        # Save metrics\n",
    "        metrics_df = pd.DataFrame([all_metrics])\n",
    "        metrics_df.to_csv(output_dir / \"metrics\" / \"single_image_metrics.csv\", index=False)\n",
    "        \n",
    "        # Save visualization\n",
    "        if self.save_visualizations:\n",
    "            viz_path = output_dir / \"visualizations\" / f\"{Path(fake_path).stem}_comparison.png\"\n",
    "            self.visualize_comparison(real_rgb, fake_rgb, real_polys, fake_polys, viz_path)\n",
    "        \n",
    "        return all_metrics, benchmark_id\n",
    "\n",
    "# Part 2: Directory Evaluation and Usage\n",
    "\n",
    "def evaluate_directory(\n",
    "    real_dir, \n",
    "    fake_dir, \n",
    "    benchmark_dir=\"benchmark-outputs\", \n",
    "    model_name=None, \n",
    "    pattern=\"*.png\", \n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Evaluate all matching images in directories with organized outputs.\"\"\"\n",
    "    evaluator = ParcelEvaluator(**kwargs)\n",
    "    \n",
    "    # Create benchmark ID and setup directories\n",
    "    benchmark_id = evaluator.create_benchmark_id(model_name)\n",
    "    output_dir = evaluator.setup_output_directory(benchmark_dir, benchmark_id)\n",
    "    \n",
    "    # Save configuration\n",
    "    evaluator.save_config(output_dir)\n",
    "    \n",
    "    # Get all matching files\n",
    "    real_dir = Path(real_dir)\n",
    "    fake_dir = Path(fake_dir)\n",
    "    real_files = sorted(real_dir.glob(pattern))\n",
    "    fake_files = sorted(fake_dir.glob(pattern))\n",
    "    \n",
    "    if len(real_files) != len(fake_files):\n",
    "        raise ValueError(f\"Number of files doesn't match: {len(real_files)} vs {len(fake_files)}\")\n",
    "    \n",
    "    # Store results\n",
    "    all_results = []\n",
    "    \n",
    "    for real_file, fake_file in tqdm(zip(real_files, fake_files), \n",
    "                                    total=len(real_files),\n",
    "                                    desc=\"Processing images\"):\n",
    "        try:\n",
    "            metrics, _ = evaluator.evaluate(\n",
    "                real_file, \n",
    "                fake_file, \n",
    "                output_dir / \"visualizations\"\n",
    "            )\n",
    "            metrics['file_name'] = fake_file.name\n",
    "            all_results.append(metrics)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {fake_file.name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save detailed results\n",
    "    df.to_csv(output_dir / \"metrics\" / \"detailed_metrics.csv\", index=False)\n",
    "    \n",
    "    # Compute and save summary statistics\n",
    "    summary_stats = df.describe()\n",
    "    summary_stats.to_csv(output_dir / \"metrics\" / \"summary_statistics.csv\")\n",
    "    \n",
    "    # Save averages in a more readable format\n",
    "    avg_metrics = df.mean(numeric_only=True)\n",
    "    summary_dict = {\n",
    "        'average_metrics': avg_metrics.to_dict(),\n",
    "        'total_images_processed': len(all_results),\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / \"metrics\" / \"summary.json\", 'w') as f:\n",
    "        json.dump(summary_dict, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nResults saved to: {output_dir}\")\n",
    "    print(\"\\nAverage Metrics:\")\n",
    "    print(\"-\" * 50)\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return df, benchmark_id\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example paths\n",
    "    fake_path = \"../data/ny-brooklyn/ma-boston-p2p-500-150-v100/test_latest_500e-Brooklyn/images/combined_200035_fake_B.png\"\n",
    "    real_path = \"../data/ny-brooklyn/ma-boston-p2p-500-150-v100/test_latest_500e-Brooklyn/images/combined_200035_real_B.png\"\n",
    "    \n",
    "    # Single image evaluation\n",
    "    evaluator = ParcelEvaluator(\n",
    "        min_area=50,\n",
    "        color_dist_threshold=30,\n",
    "        win_size_for_ssim=3,\n",
    "        save_visualizations=True\n",
    "    )\n",
    "    \n",
    "    metrics, benchmark_id = evaluator.evaluate(\n",
    "        real_path, \n",
    "        fake_path, \n",
    "        model_name=\"pix2pix_boston\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBenchmark ID: {benchmark_id}\")\n",
    "    print(\"\\nMetrics for single image:\")\n",
    "    print(\"-\" * 50)\n",
    "    for metric, value in metrics.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # For directory evaluation, uncomment and modify paths:\n",
    "    \"\"\"\n",
    "    df, benchmark_id = evaluate_directory(\n",
    "        real_dir=\"path/to/real/images\",\n",
    "        fake_dir=\"path/to/fake/images\",\n",
    "        model_name=\"pix2pix_boston\",\n",
    "        pattern=\"*.png\",\n",
    "        min_area=50,\n",
    "        color_dist_threshold=30\n",
    "    )\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
