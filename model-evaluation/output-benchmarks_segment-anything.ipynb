{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Parcel Detection and Benchmarking System - Extended Metrics\n",
      "===========================================================\n",
      "CUDA available: NVIDIA GeForce RTX 3070 Ti\n",
      "Memory allocated: 0.0 MB\n",
      "Memory reserved: 0.0 MB\n",
      "Valid folders found:\n",
      "  - brooklyn-boston-model: ../data/ny-brooklyn/ma-boston-p2p-500-150-v100/test_latest_500e-Brooklyn/images\n",
      "  - brooklyn-charlotte-model: ../data/ny-brooklyn/nc-charlotte-500-150-v100/test_latest_500e-Brooklyn/images\n",
      "  - brooklyn-manhattan-model: ../data/ny-brooklyn/ny-manhattan-p2p-500-150-v100/test_latest_500e-Brooklyn/images\n",
      "  - brooklyn-pittsburgh-model: ../data/ny-brooklyn/pa-pittsburgh-p2p-500-150-v100/test_latest_500e-Brooklyn/images\n",
      "\n",
      "Output directory: benchmark-output/brooklyn_n5_20241222_1422\n",
      "\n",
      "Processing brooklyn-boston-model...\n",
      "Scanning directory: ../data/ny-brooklyn/ma-boston-p2p-500-150-v100/test_latest_500e-Brooklyn/images\n",
      "Sampling 5 pairs from 1000 total\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3747794b6354bd4b8d912975487c931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing image pairs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAM checkpoint...\n",
      "Model initialized successfully\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "\n",
      "Processing brooklyn-charlotte-model...\n",
      "Scanning directory: ../data/ny-brooklyn/nc-charlotte-500-150-v100/test_latest_500e-Brooklyn/images\n",
      "Sampling 5 pairs from 1000 total\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c42fda26b1e4c1d93b5a899759f6dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing image pairs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAM checkpoint...\n",
      "Model initialized successfully\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error generating reports: Object of type int64 is not JSON serializable\n",
      "\n",
      "Processing brooklyn-manhattan-model...\n",
      "Scanning directory: ../data/ny-brooklyn/ny-manhattan-p2p-500-150-v100/test_latest_500e-Brooklyn/images\n",
      "Sampling 5 pairs from 1000 total\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1f61d45b034a06a044449d46316e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing image pairs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAM checkpoint...\n",
      "Model initialized successfully\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "\n",
      "Processing brooklyn-pittsburgh-model...\n",
      "Scanning directory: ../data/ny-brooklyn/pa-pittsburgh-p2p-500-150-v100/test_latest_500e-Brooklyn/images\n",
      "Sampling 5 pairs from 1000 total\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4317ee1d0af04a60a04716fb17faad8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing image pairs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAM checkpoint...\n",
      "Model initialized successfully\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "Error in calculate_metrics: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n",
      "\n",
      "Generating overall summary across all folders...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import urllib.request\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "# Shapely 2.0: no longer supports 'from shapely import hausdorff'\n",
    "# only import the geometry classes and ops we need directly.\n",
    "from shapely.geometry import Polygon, LineString\n",
    "from shapely.ops import unary_union  # Possibly used in your code\n",
    "# For older Shapely fallback, do a local import in the try/except below.\n",
    "\n",
    "# skimage metrics for SSIM, MSE, PSNR\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error, peak_signal_noise_ratio\n",
    "\n",
    "# KL-divergence from scipy\n",
    "from scipy.stats import entropy as kl_divergence\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "################################################################################\n",
    "# Memory Management / Global Config\n",
    "################################################################################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.set_per_process_memory_fraction(0.7)  # Use 70% of available memory\n",
    "    torch.backends.cuda.max_split_size_mb = 128\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128,garbage_collection_threshold:0.8,expandable_segments:True'\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Utility function for thorough memory cleanup.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "TEST_FOLDERS = {\n",
    "    'brooklyn-boston-model': \"../data/ny-brooklyn/ma-boston-p2p-500-150-v100/test_latest_500e-Brooklyn/images\",\n",
    "    'brooklyn-charlotte-model': \"../data/ny-brooklyn/nc-charlotte-500-150-v100/test_latest_500e-Brooklyn/images\",\n",
    "    'brooklyn-manhattan-model': \"../data/ny-brooklyn/ny-manhattan-p2p-500-150-v100/test_latest_500e-Brooklyn/images\",\n",
    "    'brooklyn-pittsburgh-model': \"../data/ny-brooklyn/pa-pittsburgh-p2p-500-150-v100/test_latest_500e-Brooklyn/images\",\n",
    "}\n",
    "\n",
    "SAMPLE_SIZE = 5  # down from 1000 to 5 for testing\n",
    "\n",
    "def generate_output_dir(test_folders, sample_size):\n",
    "    first_folder = list(test_folders.keys())[0]\n",
    "    base_name = first_folder.split('-')[0]\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    identifier = f\"{base_name}_n{sample_size}_{timestamp}\"\n",
    "    return os.path.join(\"benchmark-output\", identifier)\n",
    "\n",
    "OUTPUT_DIR = generate_output_dir(TEST_FOLDERS, SAMPLE_SIZE)\n",
    "\n",
    "def download_sam_checkpoint():\n",
    "    \"\"\"Download SAM checkpoint if needed.\"\"\"\n",
    "    checkpoint_path = \"sam_vit_h_4b8939.pth\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(\"Downloading SAM checkpoint...\")\n",
    "        url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n",
    "        urllib.request.urlretrieve(url, checkpoint_path)\n",
    "        print(\"Download complete!\")\n",
    "    return checkpoint_path\n",
    "\n",
    "SAM_CHECKPOINT = download_sam_checkpoint()\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "################################################################################\n",
    "# Configuration Parameters\n",
    "################################################################################\n",
    "\n",
    "BUILDING_DETECTION = {\n",
    "    'confidence_threshold': 0.5,\n",
    "    'min_area': 50,\n",
    "    'grid_points': 4,\n",
    "    'batch_size': 1,\n",
    "    'max_image_size': 512\n",
    "}\n",
    "\n",
    "GRID_DETECTION = {\n",
    "    'min_line_length': 50,\n",
    "    'angle_tolerance': 5,\n",
    "    'grid_spacing': 85,\n",
    "}\n",
    "\n",
    "BLOCK_DETECTION = {\n",
    "    'clustering_distance': 50,\n",
    "    'min_block_size': 3,\n",
    "}\n",
    "\n",
    "GEOMETRY_PARAMS = {\n",
    "    'smoothness_window': 3,\n",
    "    'corner_angle_tolerance': 5,\n",
    "    'parallel_edge_tolerance': 5,\n",
    "}\n",
    "\n",
    "VIZ_PARAMS = {\n",
    "    'figure_size': (20, 15),\n",
    "    'dpi': 150,\n",
    "    'parcel_color': 'red',\n",
    "    'grid_line_color': 'yellow',\n",
    "    'line_width': 1,\n",
    "    'heatmap_cmap': 'hot',\n",
    "}\n",
    "\n",
    "ENTROPY_PARAMS = {\n",
    "    'cell_size': 32,\n",
    "    'angle_bins': 36,\n",
    "    'neighbor_threshold': 10\n",
    "}\n",
    "\n",
    "################################################################################\n",
    "# Detector / Entropy\n",
    "################################################################################\n",
    "\n",
    "class EntropyCalculator:\n",
    "    \"\"\"Memory-efficient entropy calculations.\"\"\"\n",
    "    \n",
    "    def __init__(self, params=ENTROPY_PARAMS):\n",
    "        self.params = params\n",
    "    \n",
    "    def compute_shannon_entropy(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        probabilities = probabilities[probabilities > 0]\n",
    "        return -np.sum(probabilities * np.log2(probabilities))\n",
    "    \n",
    "    def create_spatial_grid(self, parcels, shape):\n",
    "        \"\"\"Create spatial occupation grid (for spatial entropy).\"\"\"\n",
    "        cell_size = self.params['cell_size']\n",
    "        grid_h, grid_w = shape[0] // cell_size, shape[1] // cell_size\n",
    "        grid = np.zeros((grid_h, grid_w))\n",
    "        \n",
    "        batch_size = 50\n",
    "        for i in range(0, len(parcels), batch_size):\n",
    "            batch_parcels = parcels[i:i + batch_size]\n",
    "            for parcel in batch_parcels:\n",
    "                try:\n",
    "                    coords = np.array(parcel.exterior.coords).astype(np.int32)\n",
    "                    mask = np.zeros(shape, dtype=np.uint8)\n",
    "                    cv2.fillPoly(mask, [coords], 1)\n",
    "                    \n",
    "                    for row_i in range(grid_h):\n",
    "                        for col_j in range(grid_w):\n",
    "                            cell = mask[\n",
    "                                row_i*cell_size : (row_i+1)*cell_size,\n",
    "                                col_j*cell_size : (col_j+1)*cell_size\n",
    "                            ]\n",
    "                            grid[row_i, col_j] += np.sum(cell) > 0\n",
    "                except Exception:\n",
    "                    continue\n",
    "            cleanup_memory()\n",
    "        \n",
    "        return grid\n",
    "    \n",
    "    def compute_all_entropy_metrics(self, parcels, shape):\n",
    "        \"\"\"Compute spatial, size, complexity entropies, plus total.\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        try:\n",
    "            # Spatial Entropy\n",
    "            grid = self.create_spatial_grid(parcels, shape)\n",
    "            total_occupied = np.sum(grid > 0)\n",
    "            if total_occupied > 0:\n",
    "                spatial_probs = grid[grid > 0] / total_occupied\n",
    "                metrics['spatial_entropy'] = self.compute_shannon_entropy(spatial_probs)\n",
    "            else:\n",
    "                metrics['spatial_entropy'] = 0\n",
    "            \n",
    "            del grid\n",
    "            cleanup_memory()\n",
    "            \n",
    "            # Size Entropy\n",
    "            areas = []\n",
    "            batch_size = 50\n",
    "            for i in range(0, len(parcels), batch_size):\n",
    "                batch = parcels[i:i + batch_size]\n",
    "                areas.extend([p.area for p in batch])\n",
    "                cleanup_memory()\n",
    "            \n",
    "            if areas:\n",
    "                hist, _ = np.histogram(areas, bins='auto', density=True)\n",
    "                size_probs = hist[hist > 0] / np.sum(hist[hist > 0])\n",
    "                metrics['size_entropy'] = self.compute_shannon_entropy(size_probs)\n",
    "            else:\n",
    "                metrics['size_entropy'] = 0\n",
    "            del areas\n",
    "            cleanup_memory()\n",
    "            \n",
    "            # Complexity Entropy (exterior coords length)\n",
    "            complexities = []\n",
    "            for i in range(0, len(parcels), batch_size):\n",
    "                batch = parcels[i:i + batch_size]\n",
    "                complexities.extend([len(p.exterior.coords) for p in batch])\n",
    "                cleanup_memory()\n",
    "            \n",
    "            if complexities:\n",
    "                hist, _ = np.histogram(complexities, bins='auto', density=True)\n",
    "                complexity_probs = hist[hist > 0] / np.sum(hist[hist > 0])\n",
    "                metrics['complexity_entropy'] = self.compute_shannon_entropy(complexity_probs)\n",
    "            else:\n",
    "                metrics['complexity_entropy'] = 0\n",
    "            del complexities\n",
    "            cleanup_memory()\n",
    "            \n",
    "            # Total Entropy\n",
    "            metrics['total_entropy'] = np.mean([\n",
    "                metrics['spatial_entropy'],\n",
    "                metrics['size_entropy'],\n",
    "                metrics['complexity_entropy']\n",
    "            ])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error computing entropy metrics: {str(e)}\")\n",
    "            metrics = {\n",
    "                'spatial_entropy': 0,\n",
    "                'size_entropy': 0,\n",
    "                'complexity_entropy': 0,\n",
    "                'total_entropy': 0\n",
    "            }\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "class MemoryEfficientDetector:\n",
    "    \"\"\"Memory-efficient building-parcel detector using SAM.\"\"\"\n",
    "    \n",
    "    def __init__(self, sam_checkpoint, device='cuda'):\n",
    "        self.checkpoint_path = sam_checkpoint\n",
    "        self.device = device\n",
    "        self.sam = None\n",
    "        self.predictor = None\n",
    "        self.entropy_calc = EntropyCalculator()\n",
    "    \n",
    "    def initialize_model(self):\n",
    "        \"\"\"Initialize model with careful memory management.\"\"\"\n",
    "        try:\n",
    "            self.cleanup()\n",
    "            \n",
    "            print(\"Loading SAM checkpoint...\")\n",
    "            with open(self.checkpoint_path, \"rb\") as f:\n",
    "                state_dict = torch.load(f, map_location='cpu')\n",
    "            \n",
    "            from segment_anything import SamPredictor, sam_model_registry\n",
    "            self.sam = sam_model_registry[\"vit_h\"](checkpoint=None)\n",
    "            self.sam.load_state_dict(state_dict)\n",
    "            \n",
    "            self.sam = self.sam.to(device=self.device, dtype=torch.float16)\n",
    "            self.predictor = SamPredictor(self.sam)\n",
    "            \n",
    "            print(\"Model initialized successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing model: {e}\")\n",
    "            self.cleanup()\n",
    "            return False\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Cleanup resources.\"\"\"\n",
    "        if getattr(self, 'predictor', None) is not None:\n",
    "            self.predictor.reset_image()\n",
    "            del self.predictor\n",
    "            self.predictor = None\n",
    "        if getattr(self, 'sam', None) is not None:\n",
    "            del self.sam\n",
    "            self.sam = None\n",
    "        cleanup_memory()\n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Memory-efficient image preprocessing.\"\"\"\n",
    "        try:\n",
    "            h, w = image.shape[:2]\n",
    "            max_size = BUILDING_DETECTION['max_image_size']\n",
    "            scale = min(max_size/h, max_size/w)\n",
    "            \n",
    "            if scale < 1:\n",
    "                new_h, new_w = int(h*scale), int(w*scale)\n",
    "                image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            enhanced = clahe.apply(gray)\n",
    "            \n",
    "            return enhanced, image, scale\n",
    "        except Exception as e:\n",
    "            print(f\"Error in preprocessing: {e}\")\n",
    "            return None, None, None\n",
    "    \n",
    "    def detect_grid_pattern(self, image):\n",
    "        \"\"\"Detect grid lines in the image.\"\"\"\n",
    "        try:\n",
    "            lsd = cv2.createLineSegmentDetector()\n",
    "            edges = cv2.Canny(image, 50, 150)\n",
    "            lines = lsd.detect(edges)[0]\n",
    "            \n",
    "            if lines is None:\n",
    "                return [], []\n",
    "            \n",
    "            filtered_lines = []\n",
    "            angles = []\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = map(int, line[0])\n",
    "                length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "                angle = np.degrees(np.arctan2(y2 - y1, x2 - x1)) % 180\n",
    "                if length > GRID_DETECTION['min_line_length']:\n",
    "                    filtered_lines.append(line[0])\n",
    "                    angles.append(angle)\n",
    "            \n",
    "            if angles:\n",
    "                hist, _ = np.histogram(angles, bins=180, range=(0,180))\n",
    "                peak_indices = hist > (np.mean(hist) + np.std(hist))\n",
    "                peak_angles = np.where(peak_indices)[0]\n",
    "                return filtered_lines, peak_angles\n",
    "            return [], []\n",
    "        except Exception as e:\n",
    "            print(f\"Error in grid detection: {e}\")\n",
    "            return [], []\n",
    "        finally:\n",
    "            cleanup_memory()\n",
    "    \n",
    "    def process_single_image(self, image):\n",
    "        \"\"\"Process a single image to find parcels and compute entropies.\"\"\"\n",
    "        try:\n",
    "            enhanced, orig_image, scale = self.preprocess_image(image)\n",
    "            if enhanced is None:\n",
    "                return None\n",
    "            \n",
    "            # Grid detection\n",
    "            grid_lines, dom_angles = self.detect_grid_pattern(enhanced)\n",
    "            \n",
    "            # Contours for parcels\n",
    "            edges = cv2.Canny(enhanced, 50, 150)\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            parcels = []\n",
    "            batch_size = 50\n",
    "            for i in range(0, len(contours), batch_size):\n",
    "                for cnt in contours[i:i+batch_size]:\n",
    "                    try:\n",
    "                        area = cv2.contourArea(cnt)\n",
    "                        if area < BUILDING_DETECTION['min_area']:\n",
    "                            continue\n",
    "                        epsilon = 0.02 * cv2.arcLength(cnt, True)\n",
    "                        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "                        if len(approx) < 4 or len(approx) > 8:\n",
    "                            continue\n",
    "                        coords = np.squeeze(approx).reshape(-1, 2)\n",
    "                        poly = Polygon(coords)\n",
    "                        if poly.is_valid and poly.area >= BUILDING_DETECTION['min_area']:\n",
    "                            parcels.append(poly)\n",
    "                    except:\n",
    "                        continue\n",
    "                cleanup_memory()\n",
    "            \n",
    "            # Entropy\n",
    "            entropy_metrics = self.entropy_calc.compute_all_entropy_metrics(parcels, image.shape[:2])\n",
    "            \n",
    "            return {\n",
    "                'parcels': parcels,\n",
    "                'grid_lines': grid_lines,\n",
    "                'dominant_angles': dom_angles,\n",
    "                'entropy_metrics': entropy_metrics,\n",
    "                'shape': image.shape[:2],\n",
    "                'scale': scale\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            cleanup_memory()\n",
    "    \n",
    "    def process_image_pair(self, fake_img, real_img):\n",
    "        \"\"\"Process an already-initialized model with one pair (fake, real).\"\"\"\n",
    "        try:\n",
    "            # Fake\n",
    "            fake_results = self.process_single_image(fake_img)\n",
    "            # Real\n",
    "            real_results = self.process_single_image(real_img)\n",
    "            return fake_results, real_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error in process_image_pair: {e}\")\n",
    "            return None, None\n",
    "\n",
    "################################################################################\n",
    "# Visualizer\n",
    "################################################################################\n",
    "\n",
    "class MemoryEfficientVisualizer:\n",
    "    \"\"\"Memory-efficient visualization class.\"\"\"\n",
    "    \n",
    "    def __init__(self, viz_params=VIZ_PARAMS):\n",
    "        self.viz_params = viz_params\n",
    "        matplotlib.use('Agg')  # Non-interactive backend\n",
    "    \n",
    "    def create_comparison_visualization(self, image, parcels, intermediates, metrics,\n",
    "                                        max_parcels=50):\n",
    "        \"\"\"Create a basic side-by-side or single figure comparison.\"\"\"\n",
    "        try:\n",
    "            fig = plt.figure(figsize=self.viz_params['figure_size'])\n",
    "            gs = GridSpec(2, 2, figure=fig)\n",
    "            \n",
    "            # 1. Original image with detected parcels\n",
    "            ax1 = fig.add_subplot(gs[0,0])\n",
    "            ax1.imshow(image)\n",
    "            sample_parcels = random.sample(parcels, min(len(parcels), max_parcels))\n",
    "            for parcel in sample_parcels:\n",
    "                x, y = parcel.exterior.xy\n",
    "                ax1.plot(x, y, self.viz_params['parcel_color'], linewidth=self.viz_params['line_width'])\n",
    "            ax1.set_title(f\"Parcels (showing {len(sample_parcels)} / {len(parcels)})\")\n",
    "            \n",
    "            # 2. Grid lines\n",
    "            ax2 = fig.add_subplot(gs[0,1])\n",
    "            ax2.imshow(image)\n",
    "            grid_lines = intermediates.get('grid_lines', [])\n",
    "            if len(grid_lines) > 100:\n",
    "                grid_lines = random.sample(grid_lines, 100)\n",
    "            for line in grid_lines:\n",
    "                x1, y1, x2, y2 = map(int, line)\n",
    "                ax2.plot([x1, x2], [y1, y2], self.viz_params['grid_line_color'])\n",
    "            ax2.set_title(\"Grid Pattern\")\n",
    "            \n",
    "            # 3. Metrics summary\n",
    "            ax3 = fig.add_subplot(gs[1,0])\n",
    "            metrics_text = (\n",
    "                f\"Grid Alignment: {metrics.get('grid_alignment',0):.3f}\\n\"\n",
    "                f\"Shape Regularity: {metrics.get('regularity_score',0):.3f}\\n\"\n",
    "                f\"Spatial Entropy: {metrics.get('spatial_entropy',0):.3f}\\n\"\n",
    "                f\"Size Entropy: {metrics.get('size_entropy',0):.3f}\\n\"\n",
    "                f\"Complexity Entropy: {metrics.get('complexity_entropy',0):.3f}\\n\"\n",
    "                f\"Total Entropy: {metrics.get('total_entropy',0):.3f}\\n\"\n",
    "            )\n",
    "            ax3.text(0.5, 0.5, metrics_text, ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax3.axis('off')\n",
    "            \n",
    "            # 4. Parcel Size Distribution\n",
    "            ax4 = fig.add_subplot(gs[1,1])\n",
    "            areas = [p.area for p in parcels]\n",
    "            sns.histplot(areas, ax=ax4, bins=30, kde=True)\n",
    "            ax4.set_title(\"Parcel Size Distribution\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            return fig\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {e}\")\n",
    "            plt.close('all')\n",
    "            return None\n",
    "        finally:\n",
    "            cleanup_memory()\n",
    "\n",
    "################################################################################\n",
    "# Benchmarker - Additional Metrics\n",
    "################################################################################\n",
    "\n",
    "class MemoryEfficientBenchmarker:\n",
    "    \"\"\"Benchmark class that uses the MemoryEfficientDetector and visualizer.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.detector = None\n",
    "        self.visualizer = MemoryEfficientVisualizer()\n",
    "    \n",
    "    def initialize_detector(self):\n",
    "        \"\"\"Initialize the SAM-based detector once.\"\"\"\n",
    "        try:\n",
    "            if self.detector is not None:\n",
    "                self.detector.cleanup()\n",
    "                del self.detector\n",
    "                cleanup_memory()\n",
    "            \n",
    "            self.detector = MemoryEfficientDetector(SAM_CHECKPOINT, device=DEVICE)\n",
    "            return self.detector.initialize_model()\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing detector: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Cleanup resources.\"\"\"\n",
    "        if self.detector is not None:\n",
    "            self.detector.cleanup()\n",
    "            del self.detector\n",
    "            self.detector = None\n",
    "        cleanup_memory()\n",
    "    \n",
    "    def process_single_pair_with_existing_detector(self, fake_path, real_path, output_dir=None):\n",
    "        \"\"\"Process a single pair with the already-initialized model.\"\"\"\n",
    "        try:\n",
    "            fake_img = cv2.imread(fake_path)\n",
    "            real_img = cv2.imread(real_path)\n",
    "            if fake_img is None or real_img is None:\n",
    "                print(f\"Error loading images: {fake_path}, {real_path}\")\n",
    "                return None\n",
    "            \n",
    "            # Convert to RGB\n",
    "            fake_img = cv2.cvtColor(fake_img, cv2.COLOR_BGR2RGB)\n",
    "            real_img = cv2.cvtColor(real_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            fake_results, real_results = self.detector.process_image_pair(fake_img, real_img)\n",
    "            if fake_results and real_results:\n",
    "                metrics = self.calculate_metrics(fake_results, real_results, fake_img, real_img)\n",
    "                \n",
    "                # Identify the file/pair\n",
    "                base_name = os.path.basename(fake_path)\n",
    "                # e.g., combined_123_fake_B.png => file_id = \"123\"\n",
    "                metrics['file_id'] = base_name.split('_')[1]\n",
    "                metrics['fake_path'] = fake_path\n",
    "                metrics['real_path'] = real_path\n",
    "                \n",
    "                # Visualization\n",
    "                if output_dir:\n",
    "                    fig = self.visualizer.create_comparison_visualization(\n",
    "                        fake_img, fake_results['parcels'], fake_results, metrics\n",
    "                    )\n",
    "                    if fig is not None:\n",
    "                        fig.savefig(\n",
    "                            os.path.join(output_dir, f\"comparison_{metrics['file_id']}.png\"),\n",
    "                            dpi=self.visualizer.viz_params['dpi'],\n",
    "                            bbox_inches='tight'\n",
    "                        )\n",
    "                        plt.close(fig)\n",
    "                \n",
    "                return metrics\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing pair: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_metrics(self, fake_results, real_results, fake_img, real_img):\n",
    "        \"\"\"\n",
    "        Calculate comparison metrics, including:\n",
    "          - existing grid/entropy/regularity\n",
    "          - IoU / Dice / Hausdorff\n",
    "          - shape descriptors\n",
    "          - MSE / PSNR / SSIM (raster-based)\n",
    "          - distribution overlap (KL)\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        try:\n",
    "            # ------------------------------------------------------------------\n",
    "            # Existing metrics from the previous code\n",
    "            # ------------------------------------------------------------------\n",
    "            fake_parcels = fake_results['parcels']\n",
    "            real_parcels = real_results['parcels']\n",
    "            \n",
    "            # Basic ratio: #fake parcels / #real parcels\n",
    "            if fake_parcels and real_parcels:\n",
    "                metrics['parcel_count_ratio'] = (\n",
    "                    len(fake_parcels) / max(len(real_parcels), 1)\n",
    "                )\n",
    "            else:\n",
    "                metrics['parcel_count_ratio'] = 0\n",
    "            \n",
    "            # Some measure of \"grid alignment\" (already in code)\n",
    "            if fake_parcels and fake_results.get('grid_lines'):\n",
    "                metrics['grid_alignment'] = self.compute_grid_alignment(\n",
    "                    fake_parcels, fake_results['grid_lines']\n",
    "                )\n",
    "            else:\n",
    "                metrics['grid_alignment'] = 0\n",
    "            \n",
    "            # \"Shape regularity\" measure\n",
    "            if fake_parcels:\n",
    "                metrics['regularity_score'] = self.compute_shape_regularity(fake_parcels)\n",
    "            else:\n",
    "                metrics['regularity_score'] = 0\n",
    "            \n",
    "            # Copy over fake's entropy metrics\n",
    "            if fake_results.get('entropy_metrics'):\n",
    "                metrics.update(fake_results['entropy_metrics'])\n",
    "            \n",
    "            # Compare to real entropy\n",
    "            if real_results.get('entropy_metrics'):\n",
    "                for key, val in fake_results['entropy_metrics'].items():\n",
    "                    if key in real_results['entropy_metrics']:\n",
    "                        real_val = real_results['entropy_metrics'][key]\n",
    "                        metrics[f\"relative_{key}\"] = abs(val - real_val) / max(real_val, 1e-6)\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # 1. IoU & Dice & Hausdorff Distances\n",
    "            # ------------------------------------------------------------------\n",
    "            iou_scores = []\n",
    "            dice_scores = []\n",
    "            hausdorff_dists = []\n",
    "            \n",
    "            used_real_indices = set()\n",
    "            for fpar in fake_parcels:\n",
    "                best_iou = 0\n",
    "                best_idx = -1\n",
    "                for idx, rpar in enumerate(real_parcels):\n",
    "                    if idx in used_real_indices:\n",
    "                        continue\n",
    "                    if not fpar.is_valid or not rpar.is_valid:\n",
    "                        continue\n",
    "                    inter_area = fpar.intersection(rpar).area\n",
    "                    union_area = fpar.union(rpar).area\n",
    "                    iou = inter_area / union_area if union_area > 0 else 0\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_idx = idx\n",
    "                if best_idx >= 0:\n",
    "                    used_real_indices.add(best_idx)\n",
    "                    rpar = real_parcels[best_idx]\n",
    "                    \n",
    "                    # Dice\n",
    "                    inter_area = fpar.intersection(rpar).area\n",
    "                    area_sum = fpar.area + rpar.area\n",
    "                    dice_val = (2.0 * inter_area / area_sum) if area_sum > 0 else 0\n",
    "                    \n",
    "                    # Hausdorff\n",
    "                    try:\n",
    "                        # Shapely 2.0+ method\n",
    "                        hdist = fpar.hausdorff_distance(rpar)\n",
    "                    except AttributeError:\n",
    "                        # Shapely < 2.0 fallback\n",
    "                        from shapely.ops import hausdorff_distance\n",
    "                        hdist = hausdorff_distance(fpar, rpar)\n",
    "                    \n",
    "                    iou_scores.append(best_iou)\n",
    "                    dice_scores.append(dice_val)\n",
    "                    hausdorff_dists.append(hdist)\n",
    "            \n",
    "            metrics['mean_iou'] = np.mean(iou_scores) if iou_scores else 0\n",
    "            metrics['mean_dice'] = np.mean(dice_scores) if dice_scores else 0\n",
    "            metrics['mean_hausdorff'] = np.mean(hausdorff_dists) if hausdorff_dists else 0\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # 2. Shape Descriptors (circularity)\n",
    "            # ------------------------------------------------------------------\n",
    "            def compute_circularity_stats(parcels):\n",
    "                circs = []\n",
    "                for p in parcels:\n",
    "                    if not p.is_valid:\n",
    "                        continue\n",
    "                    area = p.area\n",
    "                    perimeter = p.length\n",
    "                    if perimeter > 1e-9:\n",
    "                        circ = 4.0 * np.pi * (area / (perimeter * perimeter))\n",
    "                        circs.append(circ)\n",
    "                return np.mean(circs) if circs else 0\n",
    "            \n",
    "            fake_circ = compute_circularity_stats(fake_parcels)\n",
    "            real_circ = compute_circularity_stats(real_parcels)\n",
    "            metrics['circularity_fake'] = fake_circ\n",
    "            metrics['circularity_real'] = real_circ\n",
    "            metrics['circularity_diff'] = abs(fake_circ - real_circ)\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # 3. MSE / PSNR / SSIM (raster-based)\n",
    "            # ------------------------------------------------------------------\n",
    "            if fake_img.shape == real_img.shape:\n",
    "                fake_float = fake_img.astype(np.float32) / 255.0\n",
    "                real_float = real_img.astype(np.float32) / 255.0\n",
    "                \n",
    "                # MSE\n",
    "                mse_val = mean_squared_error(real_float, fake_float)\n",
    "                # PSNR\n",
    "                psnr_val = peak_signal_noise_ratio(real_float, fake_float, data_range=1.0)\n",
    "                # SSIM\n",
    "                ssim_val = ssim(real_float, fake_float, data_range=1.0, multichannel=True)\n",
    "                \n",
    "                metrics['mse'] = mse_val\n",
    "                metrics['psnr'] = psnr_val\n",
    "                metrics['ssim'] = ssim_val\n",
    "            else:\n",
    "                metrics['mse'] = 0\n",
    "                metrics['psnr'] = 0\n",
    "                metrics['ssim'] = 0\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # 4. Distribution Overlap (KL) on area\n",
    "            # ------------------------------------------------------------------\n",
    "            fake_areas = [p.area for p in fake_parcels if p.is_valid]\n",
    "            real_areas = [p.area for p in real_parcels if p.is_valid]\n",
    "            \n",
    "            if len(fake_areas) > 1 and len(real_areas) > 1:\n",
    "                all_areas = np.concatenate([fake_areas, real_areas])\n",
    "                bins = np.histogram_bin_edges(all_areas, bins='auto')\n",
    "                fake_hist, _ = np.histogram(fake_areas, bins=bins, density=True)\n",
    "                real_hist, _ = np.histogram(real_areas, bins=bins, density=True)\n",
    "                kl_val = kl_divergence(fake_hist + 1e-9, real_hist + 1e-9)\n",
    "                metrics['kl_div_area'] = kl_val\n",
    "            else:\n",
    "                metrics['kl_div_area'] = 0\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in calculate_metrics: {e}\")\n",
    "        return metrics\n",
    "    \n",
    "    def compute_grid_alignment(self, parcels, grid_lines, batch_size=50):\n",
    "        \"\"\"Measure alignment of each parcel edge to the dominant grid lines.\"\"\"\n",
    "        if not parcels or not grid_lines:\n",
    "            return 0\n",
    "        alignment_scores = []\n",
    "        try:\n",
    "            for i in range(0, len(parcels), batch_size):\n",
    "                batch = parcels[i:i+batch_size]\n",
    "                for parcel in batch:\n",
    "                    coords = list(parcel.exterior.coords)\n",
    "                    parcel_lines = [LineString([coords[j], coords[j+1]]) for j in range(len(coords)-1)]\n",
    "                    \n",
    "                    angles = []\n",
    "                    for p_line in parcel_lines:\n",
    "                        for g_line in grid_lines:\n",
    "                            g_linestring = LineString([(g_line[0], g_line[1]), (g_line[2], g_line[3])])\n",
    "                            angle = abs(\n",
    "                                np.degrees(np.arctan2(g_line[3]-g_line[1], g_line[2]-g_line[0])\n",
    "                                - np.arctan2(\n",
    "                                    p_line.coords[1][1] - p_line.coords[0][1],\n",
    "                                    p_line.coords[1][0] - p_line.coords[0][0]\n",
    "                                )) % 90\n",
    "                            )\n",
    "                            angles.append(min(angle, 90-angle))\n",
    "                    if angles:\n",
    "                        alignment_scores.append(np.mean(angles))\n",
    "            return 1 - (np.mean(alignment_scores)/45) if alignment_scores else 0\n",
    "        except Exception as e:\n",
    "            print(f\"Error computing grid alignment: {e}\")\n",
    "            return 0\n",
    "    \n",
    "    def compute_shape_regularity(self, parcels, batch_size=50):\n",
    "        \"\"\"Compute shape regularity = area(parcel)/area(minimum_rotated_rectangle), plus angle check.\"\"\"\n",
    "        if not parcels:\n",
    "            return 0\n",
    "        scores = []\n",
    "        try:\n",
    "            for i in range(0, len(parcels), batch_size):\n",
    "                for p in parcels[i:i+batch_size]:\n",
    "                    if not p.is_valid:\n",
    "                        continue\n",
    "                    min_rect = p.minimum_rotated_rectangle\n",
    "                    reg = 0\n",
    "                    if min_rect.area > 1e-9:\n",
    "                        reg = p.area / min_rect.area\n",
    "                    # If quadrilateral, check angles near 90\n",
    "                    coords = np.array(p.exterior.coords[:-1])\n",
    "                    if len(coords) == 4:\n",
    "                        angles = []\n",
    "                        for idx in range(4):\n",
    "                            v1 = coords[(idx+1)%4] - coords[idx]\n",
    "                            v2 = coords[(idx-1)%4] - coords[idx]\n",
    "                            angle = abs(90 - abs(np.degrees(np.arctan2(\n",
    "                                np.cross(v1, v2), np.dot(v1, v2)\n",
    "                            ))))\n",
    "                            angles.append(angle)\n",
    "                        angle_score = 1 - (np.mean(angles)/90)\n",
    "                        reg = (reg + angle_score)/2\n",
    "                    scores.append(reg)\n",
    "                cleanup_memory()\n",
    "            return np.mean(scores) if scores else 0\n",
    "        except Exception as e:\n",
    "            print(f\"Error computing shape regularity: {e}\")\n",
    "            return 0\n",
    "\n",
    "################################################################################\n",
    "# Report Generation\n",
    "################################################################################\n",
    "\n",
    "def create_memory_efficient_visualizations(df, output_dir):\n",
    "    \"\"\"Create some basic distribution/correlation plots for your metrics.\"\"\"\n",
    "    try:\n",
    "        # Filter columns for advanced metrics\n",
    "        metrics = [\n",
    "            col for col in df.columns\n",
    "            if col.startswith(('relative_', 'grid_', 'regularity_', 'mean_', 'mse', 'psnr', 'ssim', 'kl_div_area'))\n",
    "            or col in ('spatial_entropy','size_entropy','complexity_entropy','total_entropy')\n",
    "        ]\n",
    "        \n",
    "        # 1. Distributions\n",
    "        for metric in metrics:\n",
    "            plt.figure(figsize=(8,6))\n",
    "            sns.histplot(df[metric], kde=True)\n",
    "            plt.title(metric)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f\"{metric}_dist.png\"))\n",
    "            plt.close()\n",
    "            cleanup_memory()\n",
    "        \n",
    "        # 2. Correlation matrix\n",
    "        if len(metrics) > 1:\n",
    "            corr = df[metrics].corr()\n",
    "            plt.figure(figsize=(12,10))\n",
    "            sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)\n",
    "            plt.title(\"Metric Correlations\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, \"metric_correlations.png\"))\n",
    "            plt.close()\n",
    "            cleanup_memory()\n",
    "        \n",
    "        # 3. Box plots in small chunks\n",
    "        chunk_size = 5\n",
    "        for i in range(0, len(metrics), chunk_size):\n",
    "            chunk = metrics[i:i+chunk_size]\n",
    "            df_melted = df[chunk].melt()\n",
    "            plt.figure(figsize=(10,6))\n",
    "            sns.boxplot(data=df_melted, x='variable', y='value')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.title(f\"Boxplots (Group {i//chunk_size + 1})\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f\"boxplots_group_{i//chunk_size + 1}.png\"))\n",
    "            plt.close()\n",
    "            cleanup_memory()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating visualizations: {e}\")\n",
    "    finally:\n",
    "        cleanup_memory()\n",
    "\n",
    "def generate_memory_efficient_reports(results, output_dir):\n",
    "    \"\"\"Generate folderwise + overall reports, including new advanced metrics.\"\"\"\n",
    "    try:\n",
    "        chunk_size = 100\n",
    "        all_dfs = []\n",
    "        for i in range(0, len(results), chunk_size):\n",
    "            df_chunk = pd.DataFrame(results[i:i+chunk_size])\n",
    "            all_dfs.append(df_chunk)\n",
    "            cleanup_memory()\n",
    "        \n",
    "        df = pd.concat(all_dfs, ignore_index=True)\n",
    "        \n",
    "        # 1. Save detailed results\n",
    "        df.to_csv(os.path.join(output_dir, 'detailed_results.csv'), index=False)\n",
    "        cleanup_memory()\n",
    "        \n",
    "        # 2. Compute overall aggregates\n",
    "        metrics_to_analyze = [\n",
    "            'parcel_count_ratio','grid_alignment','regularity_score',\n",
    "            'mean_iou','mean_dice','mean_hausdorff',\n",
    "            'mse','psnr','ssim','kl_div_area',\n",
    "            'spatial_entropy','size_entropy','complexity_entropy','total_entropy'\n",
    "        ]\n",
    "        \n",
    "        aggregate_metrics = {}\n",
    "        for metric in metrics_to_analyze:\n",
    "            if metric in df.columns:\n",
    "                aggregate_metrics[metric] = {\n",
    "                    'mean': df[metric].mean(),\n",
    "                    'std': df[metric].std(),\n",
    "                    'min': df[metric].min(),\n",
    "                    'max': df[metric].max(),\n",
    "                    'median': df[metric].median()\n",
    "                }\n",
    "        \n",
    "        with open(os.path.join(output_dir, 'aggregate_metrics.json'), 'w') as f:\n",
    "            json.dump(aggregate_metrics, f, indent=4)\n",
    "        \n",
    "        # 3. Folderwise summary (average per folder)\n",
    "        if 'folder' in df.columns:\n",
    "            folderwise_cols = [\n",
    "                'spatial_entropy','size_entropy','complexity_entropy','total_entropy',\n",
    "                'mean_iou','mean_dice','mean_hausdorff','mse','psnr','ssim',\n",
    "                'kl_div_area','parcel_count_ratio','grid_alignment','regularity_score'\n",
    "            ]\n",
    "            folderwise_cols = [c for c in folderwise_cols if c in df.columns]\n",
    "            if folderwise_cols:\n",
    "                folderwise = (df.groupby('folder')[folderwise_cols].mean().reset_index())\n",
    "                folderwise.to_csv(os.path.join(output_dir, 'folderwise_metrics.csv'), index=False)\n",
    "        \n",
    "        # 4. Visualizations\n",
    "        create_memory_efficient_visualizations(df, output_dir)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating reports: {e}\")\n",
    "    finally:\n",
    "        cleanup_memory()\n",
    "\n",
    "################################################################################\n",
    "# Main Processing Logic\n",
    "################################################################################\n",
    "\n",
    "def process_test_folder(test_folder, output_dir=None, sample_size=SAMPLE_SIZE):\n",
    "    \"\"\"Process test folder with controlled sample size.\"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.join(test_folder, 'benchmark_results')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    benchmarker = MemoryEfficientBenchmarker()\n",
    "    \n",
    "    print(f\"Scanning directory: {test_folder}\")\n",
    "    image_pairs = {}\n",
    "    \n",
    "    # Regex: e.g. combined_123_fake_B.png or combined_123_real_B.png\n",
    "    for filename in os.listdir(test_folder):\n",
    "        if not filename.endswith('.png'):\n",
    "            continue\n",
    "        \n",
    "        match = re.search(r'combined_(\\d+)_(fake|real)_B\\.png', filename)\n",
    "        if not match:\n",
    "            continue\n",
    "        \n",
    "        base_num, img_type = match.group(1), match.group(2)\n",
    "        full_path = os.path.join(test_folder, filename)\n",
    "        \n",
    "        if base_num not in image_pairs:\n",
    "            image_pairs[base_num] = {'fake': None, 'real': None}\n",
    "        image_pairs[base_num][img_type] = full_path\n",
    "    \n",
    "    complete_pairs = [\n",
    "        (pair['fake'], pair['real']) for pair in image_pairs.values()\n",
    "        if pair['fake'] and pair['real']\n",
    "    ]\n",
    "    \n",
    "    if sample_size and sample_size < len(complete_pairs):\n",
    "        print(f\"Sampling {sample_size} pairs from {len(complete_pairs)} total\")\n",
    "        complete_pairs = random.sample(complete_pairs, sample_size)\n",
    "    else:\n",
    "        print(f\"Processing all {len(complete_pairs)} pairs\")\n",
    "    \n",
    "    results = []\n",
    "    with tqdm(total=len(complete_pairs), desc=\"Processing image pairs\") as pbar:\n",
    "        if benchmarker.initialize_detector():\n",
    "            for fake_path, real_path in complete_pairs:\n",
    "                try:\n",
    "                    metrics = benchmarker.process_single_pair_with_existing_detector(\n",
    "                        fake_path, real_path, output_dir\n",
    "                    )\n",
    "                    if metrics:\n",
    "                        results.append(metrics)\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError processing {os.path.basename(fake_path)}: {e}\")\n",
    "                finally:\n",
    "                    cleanup_memory()\n",
    "                pbar.update(1)\n",
    "            \n",
    "            benchmarker.cleanup()\n",
    "    \n",
    "    if results:\n",
    "        generate_memory_efficient_reports(results, output_dir)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    print(\"\\nParcel Detection and Benchmarking System - Extended Metrics\")\n",
    "    print(\"===========================================================\")\n",
    "    \n",
    "    try:\n",
    "        # Quick device check\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"Memory allocated: {torch.cuda.memory_allocated(0)/(1024**2):.1f} MB\")\n",
    "            print(f\"Memory reserved: {torch.cuda.memory_reserved(0)/(1024**2):.1f} MB\")\n",
    "        else:\n",
    "            print(\"CUDA not available, using CPU\")\n",
    "        \n",
    "        # Verify input folders\n",
    "        valid_folders = {\n",
    "            name: path for name, path in TEST_FOLDERS.items()\n",
    "            if os.path.exists(path)\n",
    "        }\n",
    "        if not valid_folders:\n",
    "            raise ValueError(\"No valid folders found!\")\n",
    "        \n",
    "        print(\"Valid folders found:\")\n",
    "        for name, path in valid_folders.items():\n",
    "            print(f\"  - {name}: {path}\")\n",
    "        \n",
    "        # Create main output\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "        print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
    "        \n",
    "        all_results = []\n",
    "        for folder_name, folder_path in valid_folders.items():\n",
    "            print(f\"\\nProcessing {folder_name}...\")\n",
    "            output_subdir = os.path.join(OUTPUT_DIR, folder_name)\n",
    "            try:\n",
    "                folder_results = process_test_folder(\n",
    "                    folder_path, output_subdir, sample_size=SAMPLE_SIZE\n",
    "                )\n",
    "                if folder_results:\n",
    "                    for r in folder_results:\n",
    "                        r['folder'] = folder_name\n",
    "                    all_results.extend(folder_results)\n",
    "                cleanup_memory()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing folder {folder_name}: {e}\")\n",
    "        \n",
    "        # Overall summary\n",
    "        if all_results:\n",
    "            print(\"\\nGenerating overall summary across all folders...\")\n",
    "            generate_memory_efficient_reports(all_results, OUTPUT_DIR)\n",
    "        \n",
    "        print(\"\\nProcessing complete!\")\n",
    "        print(f\"Results saved to: {OUTPUT_DIR}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during execution: {e}\")\n",
    "    finally:\n",
    "        cleanup_memory()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.set_per_process_memory_fraction(0.7)\n",
    "        torch.backends.cuda.max_split_size_mb = 128\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
