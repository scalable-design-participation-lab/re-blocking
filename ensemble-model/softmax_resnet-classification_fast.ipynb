{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0536fb77b88e408b8c573474a2df7868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [1/50]:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.8915, Val Loss: 0.3843, Val Accuracy: 0.4633\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340d5a364d9e4a8eb2fcd396bc714802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [2/50]:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 0.5957, Val Loss: 0.2719, Val Accuracy: 0.7121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d8f8d5019743138d386a633987a1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [3/50]:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image, ImageFile\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n",
    "# Parameters to tweak\n",
    "batch_size = 64  # 32\n",
    "learning_rate = 1e-5 #0.001\n",
    "num_epochs = 200  # 5\n",
    "checkpoint_interval = 50\n",
    "\n",
    "# Directories\n",
    "identifier = f\"softmax-resnet_{batch_size}-batch_{learning_rate}-learning_{num_epochs}-epochs\"\n",
    "class_names = ['Boston', 'Charlotte', 'Manhattan', 'Pittsburgh']\n",
    "folders = {\n",
    "    'Boston': '../data/ma-boston/buildings',\n",
    "    'Charlotte': '../data/nc-charlotte/buildings',\n",
    "    'Manhattan': '../data/ny-manhattan/buildings',\n",
    "    'Pittsburgh': '../data/pa-pittsburgh/buildings'\n",
    "}\n",
    "output_folder = os.path.join('softmax-output', identifier)\n",
    "checkpoint_dir = os.path.join(output_folder, 'checkpoints')\n",
    "model_save_path = os.path.join(output_folder, 'trained-model.pth')\n",
    "loss_log_path = os.path.join(output_folder, 'loss-log.json')\n",
    "new_image_path = '../data/ny-brooklyn/buildings/buildings_1370.jpg'\n",
    "predictions_output_file = os.path.join(output_folder, 'predictions.txt')\n",
    "\n",
    "# More Parameters\n",
    "normalize_mean = [0.485, 0.456, 0.406]\n",
    "normalize_std = [0.229, 0.224, 0.225]\n",
    "num_classes = len(class_names)\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Define output folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CityDataset(Dataset):\n",
    "    def __init__(self, folders, transform=None, max_images_per_class=500):  # Limit images per class\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(folders.keys())}\n",
    "\n",
    "        for class_name, folder in folders.items():\n",
    "            class_images = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            selected_images = random.sample(class_images, min(max_images_per_class, len(class_images)))\n",
    "            self.image_paths.extend(selected_images)\n",
    "            self.labels.extend([self.class_to_idx[class_name]] * len(selected_images))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Create dataset\n",
    "dataset = CityDataset(folders)\n",
    "\n",
    "# Define transformations with data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to a smaller, fixed size\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normalize_mean, std=normalize_std),\n",
    "])\n",
    "\n",
    "# Update dataset with transform\n",
    "dataset.transform = transform\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load a pre-trained ResNet18 model (smaller than ResNet50)\n",
    "weights = models.ResNet18_Weights.DEFAULT\n",
    "model = models.resnet18(weights=weights)\n",
    "\n",
    "# Modify the final layer to match the number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# Model training function\n",
    "def train_and_save_model(model, train_loader, val_loader, num_epochs, checkpoint_interval, checkpoint_dir):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "    val_accuracy_log = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_loss_log.append(epoch_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = correct / total\n",
    "        val_loss_log.append(val_epoch_loss)\n",
    "        val_accuracy_log.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {val_epoch_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % checkpoint_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    # Save the final model weights\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    # Save the loss and accuracy logs\n",
    "    with open(loss_log_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'train_loss': train_loss_log,\n",
    "            'val_loss': val_loss_log,\n",
    "            'val_accuracy': val_accuracy_log\n",
    "        }, f)\n",
    "\n",
    "    # Plot the loss and accuracy curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss_log, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), val_loss_log, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), val_accuracy_log)\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, 'training_curves.png'))\n",
    "    plt.close()\n",
    "\n",
    "# K-fold cross-validation function\n",
    "def k_fold_cross_validation(dataset, num_folds=3):  # Reduced number of folds\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset), 1):\n",
    "        print(f\"Fold {fold}\")\n",
    "        \n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "        \n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "        val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_subsampler)\n",
    "        \n",
    "        model = models.resnet18(weights=weights)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        model.to(device)\n",
    "        \n",
    "        train_and_save_model(model, train_loader, val_loader, num_epochs, checkpoint_interval, \n",
    "                             os.path.join(checkpoint_dir, f'fold_{fold}'))\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        fold_results.append(accuracy)\n",
    "        print(f\"Fold {fold} accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"Average accuracy across folds: {sum(fold_results) / len(fold_results):.4f}\")\n",
    "\n",
    "# Run k-fold cross-validation\n",
    "k_fold_cross_validation(dataset)\n",
    "\n",
    "# Function to predict on a new image\n",
    "def predict_image(model, image_path, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = F.softmax(outputs, dim=1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return probabilities, predicted_class\n",
    "\n",
    "# Predict on a new image\n",
    "new_image_probabilities, new_image_class = predict_image(model, new_image_path, transform)\n",
    "\n",
    "# Print and save predictions\n",
    "predictions = [f\"{class_names[i]}: {prob:.2f}\" for i, prob in enumerate(new_image_probabilities)]\n",
    "print(f\"Predictions for {new_image_path}:\")\n",
    "print(f\"Predicted class: {class_names[new_image_class]}\")\n",
    "print(\"Class probabilities:\")\n",
    "for pred in predictions:\n",
    "    print(pred)\n",
    "\n",
    "with open(predictions_output_file, 'w') as f:\n",
    "    f.write(f\"Predictions for {new_image_path}:\\n\")\n",
    "    f.write(f\"Predicted class: {class_names[new_image_class]}\\n\")\n",
    "    f.write(\"Class probabilities:\\n\")\n",
    "    for pred in predictions:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "\n",
    "print(f\"Predictions saved to {predictions_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
