{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up and model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Add the path to the `pytorch-CycleGAN-and-pix2pix` repository\n",
    "repo_path = '/Users/ls/Sites/pytorch-CycleGAN-and-pix2pix'  # Update this to your repository path\n",
    "sys.path.append(repo_path)\n",
    "\n",
    "# Import the necessary modules from the repository\n",
    "from models.pix2pix_model import Pix2PixModel\n",
    "from models.networks import define_G\n",
    "\n",
    "# Paths to your generator .pth files\n",
    "model1_path = '/Users/ls/Library/CloudStorage/GoogleDrive-l.schrage@northeastern.edu/Shared drives/Drawing Participation/Million Neighborhoods/Trained Models/ma-boston-p2p-500-150-v100/500_net_G.pth'\n",
    "model2_path = '/Users/ls/Library/CloudStorage/GoogleDrive-l.schrage@northeastern.edu/Shared drives/Drawing Participation/Million Neighborhoods/Trained Models/nc-charlotte-500-150-v100/500_net_G.pth'\n",
    "model3_path = '/Users/ls/Library/CloudStorage/GoogleDrive-l.schrage@northeastern.edu/Shared drives/Drawing Participation/Million Neighborhoods/Trained Models/ny-manhattan-p2p-500-150-v100/500_net_G.pth'\n",
    "model4_path = '/Users/ls/Library/CloudStorage/GoogleDrive-l.schrage@northeastern.edu/Shared drives/Drawing Participation/Million Neighborhoods/Trained Models/pa-pittsburgh-p2p-500-150-v100/500_net_G.pth'\n",
    "\n",
    "model_paths = [\n",
    "    model1_path,\n",
    "    model2_path,\n",
    "    model3_path,\n",
    "    model4_path\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generator(model_path):\n",
    "    # Assuming the input_nc and output_nc are set as per your training configuration\n",
    "    input_nc = 3\n",
    "    output_nc = 3\n",
    "    ngf = 64\n",
    "    netG = define_G(input_nc, output_nc, ngf, 'unet_256', norm='batch', use_dropout=False, init_type='normal', init_gain=0.02, gpu_ids=[])\n",
    "    netG.load_state_dict(torch.load(model_path))\n",
    "    return netG\n",
    "\n",
    "generators = [load_generator(path) for path in model_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Define the Ensemble Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def ensemble_output(generators, input_image):\n",
    "    outputs = [generator(input_image) for generator in generators]\n",
    "    averaged_output = torch.mean(torch.stack(outputs), dim=0)\n",
    "    return averaged_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_meta_model(meta_model, generators, dataloader):\n",
    "    meta_model.eval()\n",
    "    total_loss = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            input_image = data['A']\n",
    "            target_image = data['B']\n",
    "            generator_outputs = [generator(input_image) for generator in generators]\n",
    "            meta_input = torch.cat(generator_outputs, dim=1)\n",
    "            meta_output = meta_model(meta_input)\n",
    "            \n",
    "            loss = criterion(meta_output, target_image)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "# Assuming you have a DataLoader for your validation dataset\n",
    "val_dataset = Pix2pixDataset(dataroot='path_to_val_dataset', phase='val', transform=None)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "validation_loss = evaluate_meta_model(meta_model, generators, val_dataloader)\n",
    "print(f'Validation Loss: {validation_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define a transformation to preprocess the input image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load and preprocess your input image\n",
    "input_image_path = '/path/to/your/input/image.jpg'  # Update with your input image path\n",
    "input_image = Image.open(input_image_path).convert('RGB')\n",
    "input_tensor = transform(input_image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Generate the final output\n",
    "final_output = ensemble_output(generators, input_tensor)\n",
    "\n",
    "# Convert the output tensor to an image\n",
    "output_image = final_output.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "output_image = (output_image * 0.5 + 0.5) * 255  # Denormalize\n",
    "output_image = output_image.astype('uint8')\n",
    "\n",
    "# Display the output image\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(output_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
