{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Fold 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.optim' has no attribute 'ReduceLROnPlateau'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 381\u001b[0m\n\u001b[1;32m    378\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning Plateau: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_plateau\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# Run k-fold cross-validation\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m \u001b[43mk_fold_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# Function to predict on a new image\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_image\u001b[39m(model, image_path, transform):\n",
      "Cell \u001b[0;32mIn[2], line 276\u001b[0m, in \u001b[0;36mk_fold_cross_validation\u001b[0;34m(dataset, num_folds)\u001b[0m\n\u001b[1;32m    270\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m    271\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m    272\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features, num_classes)\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    274\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 276\u001b[0m train_loss_log, val_loss_log, val_accuracy_log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m all_train_loss_logs\u001b[38;5;241m.\u001b[39mappend(train_loss_log)\n\u001b[1;32m    282\u001b[0m all_val_loss_logs\u001b[38;5;241m.\u001b[39mappend(val_loss_log)\n",
      "Cell \u001b[0;32mIn[2], line 126\u001b[0m, in \u001b[0;36mtrain_and_save_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, checkpoint_interval, checkpoint_dir)\u001b[0m\n\u001b[1;32m    124\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m    125\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[0;32m--> 126\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceLROnPlateau\u001b[49m(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    127\u001b[0m train_loss_log \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    128\u001b[0m val_loss_log \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.optim' has no attribute 'ReduceLROnPlateau'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image, ImageFile\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Parameters to tweak\n",
    "batch_size = 64  # Reduced from 128 due to larger model\n",
    "learning_rate = 1e-4  # before 1e-3\n",
    "num_epochs = 100\n",
    "checkpoint_interval = 10\n",
    "max_images_per_class = 25000  # Set to use all images\n",
    "\n",
    "# Directories\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "identifier = f\"softmax-resnet-18_{num_epochs}-ep_{batch_size}-bs_{max_images_per_class}-images_{current_time}\"\n",
    "class_names = ['Boston', 'Charlotte', 'Manhattan', 'Pittsburgh']\n",
    "folders = { # building outlines on satellite background\n",
    "    'Boston': '../data/ma-boston/buildings',\n",
    "    'Charlotte': '../data/nc-charlotte/buildings',\n",
    "    'Manhattan': '../data/ny-manhattan/buildings',\n",
    "    'Pittsburgh': '../data/pa-pittsburgh/buildings'\n",
    "}\n",
    "output_folder = os.path.join('softmax-output', identifier)\n",
    "checkpoint_dir = os.path.join(output_folder, 'checkpoints')\n",
    "model_save_path = os.path.join(output_folder, f'trained-model_{identifier}.pth')\n",
    "loss_log_path = os.path.join(output_folder, f'loss-log_{identifier}.json')\n",
    "training_curves_path = os.path.join(output_folder, f'training-curves_{identifier}.png')\n",
    "confusion_matrix_path = os.path.join(output_folder, f'confusion-matrix_{identifier}.png')\n",
    "cross_validation_path = os.path.join(output_folder, f'cross-validation_{identifier}.png')\n",
    "misclassified_samples_path = os.path.join(output_folder, f'misclassified-samples_{identifier}.png')\n",
    "report_path = os.path.join(output_folder, f'report_{identifier}.txt')\n",
    "new_image_path = '../data/ny-brooklyn/buildings/buildings_1370.jpg'\n",
    "predictions_output_file = os.path.join(output_folder, f'predictions_{identifier}.txt')\n",
    "\n",
    "# More Parameters\n",
    "normalize_mean = [0.485, 0.456, 0.406]\n",
    "normalize_std = [0.229, 0.224, 0.225]\n",
    "num_classes = len(class_names)\n",
    "weight_decay = 1e-5  # Reduced due to large dataset (prior tests limited to 500 images per class)\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Define output folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CityDataset(Dataset):\n",
    "    def __init__(self, folders, transform=None, max_images_per_class=max_images_per_class):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(folders.keys())}\n",
    "\n",
    "        for class_name, folder in folders.items():\n",
    "            class_images = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            selected_images = random.sample(class_images, min(max_images_per_class, len(class_images)))\n",
    "            self.image_paths.extend(selected_images)\n",
    "            self.labels.extend([self.class_to_idx[class_name]] * len(selected_images))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations with data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normalize_mean, std=normalize_std),\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = CityDataset(folders, transform=transform)\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load a pre-trained ResNet50 model\n",
    "weights = models.ResNet50_Weights.DEFAULT\n",
    "model = models.resnet50(weights=weights)\n",
    "\n",
    "# Modify the final layer to match the number of classes\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(model.fc.in_features, num_classes)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Save training parameters\n",
    "training_params = {\n",
    "    \"identifier\": identifier,\n",
    "    'model': str(model),\n",
    "    'device': str(device),\n",
    "    'max_images_per_class': max_images_per_class,\n",
    "    'num_classes': num_classes,\n",
    "    'class_names': class_names,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"checkpoint_interval\": checkpoint_interval,\n",
    "    'normalize_mean': normalize_mean,\n",
    "    'normalize_std': normalize_std,\n",
    "\n",
    "}\n",
    "params_path = os.path.join(output_folder, 'training_params.json')\n",
    "with open(params_path, 'w') as f:\n",
    "    json.dump(training_params, f)\n",
    "print(f\"Training parameters saved to {params_path}\")\n",
    "\n",
    "# Model training function\n",
    "def train_and_save_model(model, train_loader, val_loader, num_epochs, checkpoint_interval, checkpoint_dir):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "    val_accuracy_log = []\n",
    "    epoch_times = []\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    total_iterations = num_epochs * len(train_loader)\n",
    "    progress_bar = tqdm(total=total_iterations, desc=\"Training Progress\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_loss_log.append(epoch_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = correct / total\n",
    "        val_loss_log.append(val_epoch_loss)\n",
    "        val_accuracy_log.append(val_accuracy)\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_epoch_loss)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_epoch_loss < best_val_loss:\n",
    "            best_val_loss = val_epoch_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - epoch_start_time\n",
    "        epoch_times.append(epoch_duration)\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            'Epoch': f'{epoch + 1}/{num_epochs}',\n",
    "            'Train Loss': f'{epoch_loss:.4f}',\n",
    "            'Val Loss': f'{val_epoch_loss:.4f}',\n",
    "            'Val Accuracy': f'{val_accuracy:.4f}',\n",
    "            'Epoch Time (s)': f'{epoch_duration:.2f}'\n",
    "        })\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % checkpoint_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}_{identifier}.pth')\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Save the loss and accuracy logs\n",
    "    with open(loss_log_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'train_loss': train_loss_log,\n",
    "            'val_loss': val_loss_log,\n",
    "            'val_accuracy': val_accuracy_log,\n",
    "            'epoch_times': epoch_times\n",
    "        }, f)\n",
    "\n",
    "    # Plot the loss and accuracy curves\n",
    "    plot_training_curves(train_loss_log, val_loss_log, val_accuracy_log)\n",
    "\n",
    "    return train_loss_log, val_loss_log, val_accuracy_log\n",
    "\n",
    "def plot_training_curves(train_loss_log, val_loss_log, val_accuracy_log):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(train_loss_log) + 1), train_loss_log, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_loss_log) + 1), val_loss_log, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(val_accuracy_log) + 1), val_accuracy_log)\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(training_curves_path)\n",
    "    plt.close()\n",
    "\n",
    "def k_fold_cross_validation(dataset, num_folds=5):\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    fold_times = []\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_train_loss_logs = []\n",
    "    all_val_loss_logs = []\n",
    "    all_val_accuracy_logs = []\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset), 1):\n",
    "        print(f\"Fold {fold}\")\n",
    "        fold_start_time = time.time()\n",
    "        \n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "        \n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "        val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_subsampler)\n",
    "        \n",
    "        model = models.resnet50(weights=weights)\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(model.fc.in_features, num_classes)\n",
    "        )\n",
    "        model.to(device)\n",
    "        \n",
    "        train_loss_log, val_loss_log, val_accuracy_log = train_and_save_model(\n",
    "            model, train_loader, val_loader, num_epochs, checkpoint_interval, \n",
    "            os.path.join(checkpoint_dir, f'fold_{fold}')\n",
    "        )\n",
    "        \n",
    "        all_train_loss_logs.append(train_loss_log)\n",
    "        all_val_loss_logs.append(val_loss_log)\n",
    "        all_val_accuracy_logs.append(val_accuracy_log)\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        fold_labels = []\n",
    "        fold_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                fold_labels.extend(labels.cpu().numpy())\n",
    "                fold_predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        fold_results.append(accuracy)\n",
    "        all_labels.extend(fold_labels)\n",
    "        all_predictions.extend(fold_predictions)\n",
    "        fold_end_time = time.time()\n",
    "        fold_duration = fold_end_time - fold_start_time\n",
    "        fold_times.append(fold_duration)\n",
    "        print(f\"Fold {fold} accuracy: {accuracy:.4f}, Time: {fold_duration:.2f} seconds\")\n",
    "    \n",
    "    average_accuracy = sum(fold_results) / len(fold_results)\n",
    "    print(f\"Average accuracy across folds: {average_accuracy:.4f}\")\n",
    "    print(f\"Average time per fold: {sum(fold_times) / len(fold_times):.2f} seconds\")\n",
    "\n",
    "    # Plot cross-validation results\n",
    "    plot_cross_validation_results(fold_results, average_accuracy, num_folds)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    # Plot misclassified samples\n",
    "    plot_misclassified_samples(dataset, all_labels, all_predictions)\n",
    "\n",
    "    # Generate classification report\n",
    "    generate_classification_report(all_labels, all_predictions)\n",
    "\n",
    "    # Calculate and save additional metrics\n",
    "    calculate_additional_metrics(all_train_loss_logs, all_val_loss_logs)\n",
    "\n",
    "def plot_cross_validation_results(fold_results, average_accuracy, num_folds):\n",
    "    plt.figure()\n",
    "    plt.bar(range(1, num_folds + 1), fold_results, tick_label=[f'Fold {i}' for i in range(1, num_folds + 1)])\n",
    "    plt.axhline(y=average_accuracy, color='r', linestyle='--', label=f'Average Accuracy: {average_accuracy:.4f}')\n",
    "    plt.title('Cross-Validation Accuracy')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(cross_validation_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_predictions):\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_misclassified_samples(dataset, all_labels, all_predictions):\n",
    "    misclassified_indices = [i for i, (label, pred) in enumerate(zip(all_labels, all_predictions)) if label != pred]\n",
    "    if misclassified_indices:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        for i, idx in enumerate(random.sample(misclassified_indices, min(25, len(misclassified_indices)))):\n",
    "            image, label = dataset[idx]\n",
    "            plt.subplot(5, 5, i + 1)\n",
    "            plt.imshow(image.permute(1, 2, 0).numpy())\n",
    "            plt.title(f'True: {class_names[label]}\\nPred: {class_names[all_predictions[idx]]}')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(misclassified_samples_path)\n",
    "        plt.close()\n",
    "\n",
    "def generate_classification_report(all_labels, all_predictions):\n",
    "    report = classification_report(all_labels, all_predictions, target_names=class_names)\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(report)\n",
    "    print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "def calculate_additional_metrics(all_train_loss_logs, all_val_loss_logs):\n",
    "    avg_train_loss_log = np.mean(all_train_loss_logs, axis=0)\n",
    "    avg_val_loss_log = np.mean(all_val_loss_logs, axis=0)\n",
    "\n",
    "    convergence_rate = (avg_train_loss_log[-1] - avg_train_loss_log[0]) / len(avg_train_loss_log)\n",
    "    overfitting_score = (avg_val_loss_log[-1] - avg_train_loss_log[-1]) / avg_val_loss_log[-1]\n",
    "    learning_plateau = np.mean(avg_val_loss_log[-5:]) - np.mean(avg_val_loss_log[:5])\n",
    "\n",
    "    with open(report_path, 'a') as f:\n",
    "        f.write(f\"\\nConvergence Rate: {convergence_rate:.4f}\\n\")\n",
    "        f.write(f\"Overfitting Score: {overfitting_score:.4f}\\n\")\n",
    "        f.write(f\"Learning Plateau: {learning_plateau:.4f}\\n\")\n",
    "\n",
    "# Run k-fold cross-validation\n",
    "k_fold_cross_validation(dataset)\n",
    "\n",
    "# Function to predict on a new image\n",
    "def predict_image(model, image_path, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = F.softmax(outputs, dim=1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return probabilities, predicted_class\n",
    "\n",
    "# Load the best model\n",
    "best_model = models.resnet50(weights=None)\n",
    "best_model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(best_model.fc.in_features, num_classes)\n",
    ")\n",
    "best_model.load_state_dict(torch.load(model_save_path))\n",
    "best_model.to(device)\n",
    "\n",
    "# Predict on a new image\n",
    "new_image_probabilities, new_image_class = predict_image(best_model, new_image_path, transform)\n",
    "\n",
    "# Print and save predictions\n",
    "predictions = [f\"{class_names[i]}: {prob:.2f}\" for i, prob in enumerate(new_image_probabilities)]\n",
    "print(f\"Predictions for {new_image_path}:\")\n",
    "print(f\"Predicted class: {class_names[new_image_class]}\")\n",
    "print(\"Class probabilities:\")\n",
    "for pred in predictions:\n",
    "    print(pred)\n",
    "\n",
    "with open(predictions_output_file, 'w') as f:\n",
    "    f.write(f\"Predictions for {new_image_path}:\\n\")\n",
    "    f.write(f\"Predicted class: {class_names[new_image_class]}\\n\")\n",
    "    f.write(\"Class probabilities:\\n\")\n",
    "    for pred in predictions:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "\n",
    "print(f\"Predictions saved to {predictions_output_file}\")\n",
    "\n",
    "# Optional: Visualize the prediction\n",
    "plt.figure(figsize=(10, 10))\n",
    "img = Image.open(new_image_path)\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Predicted: {class_names[new_image_class]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Script execution completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test classification on a different image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "# Define the classes and model path\n",
    "class_names = ['Boston', 'Charlotte', 'Manhattan', 'Pittsburgh']\n",
    "model_path = 'path/to/your/trained-model.pth'  # Update this path\n",
    "\n",
    "# Set up the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def load_model():\n",
    "    # Load the ResNet50 model\n",
    "    model = models.resnet50(weights=None)\n",
    "    model.fc = torch.nn.Sequential(\n",
    "        torch.nn.Dropout(0.5),\n",
    "        torch.nn.Linear(model.fc.in_features, len(class_names))\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def predict_image(model, image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return probabilities, predicted_class\n",
    "\n",
    "def visualize_prediction(image_path, predicted_class, probabilities):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Display the image\n",
    "    img = Image.open(image_path)\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title(f\"Predicted: {class_names[predicted_class]}\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Display the probabilities\n",
    "    bars = ax2.bar(class_names, probabilities.cpu().numpy())\n",
    "    ax2.set_ylabel('Probability')\n",
    "    ax2.set_title('Class Probabilities')\n",
    "    ax2.set_ylim([0, 1])\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Add probability values on top of each bar\n",
    "    for rect in bars:\n",
    "        height = rect.get_height()\n",
    "        ax2.text(rect.get_x() + rect.get_width()/2., height,\n",
    "                 f'{height:.2f}',\n",
    "                 ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main(image_paths):\n",
    "    model = load_model()\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        probabilities, predicted_class = predict_image(model, image_path)\n",
    "        \n",
    "        print(f\"\\nPredictions for {image_path}:\")\n",
    "        print(f\"Predicted class: {class_names[predicted_class]}\")\n",
    "        print(\"Class probabilities:\")\n",
    "        for i, prob in enumerate(probabilities):\n",
    "            print(f\"{class_names[i]}: {prob:.4f}\")\n",
    "        \n",
    "        visualize_prediction(image_path, predicted_class, probabilities)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Classify satellite images of cities.\")\n",
    "    parser.add_argument(\"image_paths\", nargs='+', help=\"Paths to the images to classify\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    main(args.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp. overwrite new image for testing purposes\n",
    "new_image_path = '../data/nc-charlotte/buildings/buildings_131.jpg'\n",
    "\n",
    "# Load model weights\n",
    "model.load_state_dict(torch.load(model_save_path, weights_only=True))\n",
    "\n",
    "# Function to classify a new image\n",
    "def classify_new_image(image_path, model, transform):\n",
    "    model.eval()\n",
    "    input_image = Image.open(image_path)\n",
    "    input_tensor = transform(input_image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output, dim=1)\n",
    "        probabilities = probabilities.cpu().numpy().flatten()\n",
    "\n",
    "    predictions = [(class_names[i], prob * 100) for i, prob in enumerate(probabilities)]\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return predictions, input_image\n",
    "\n",
    "with tqdm(total=1, desc=\"Classifying new image\", leave=False) as pbar:\n",
    "    predictions, input_image = classify_new_image(new_image_path, model, transform)\n",
    "    pbar.update(1)\n",
    "\n",
    "# Display the image\n",
    "display(input_image)\n",
    "\n",
    "# Save predictions to a file\n",
    "with open(predictions_output_file, 'w') as f:\n",
    "    f.write(f'Image path: {new_image_path}\\n')  # Write the image path\n",
    "    for label, percentage in predictions:\n",
    "        f.write(f'Predicted class: {label}, Confidence: {percentage:.2f}%\\n')\n",
    "        print(f'Predicted class: {label}, Confidence: {percentage:.2f}%')\n",
    "\n",
    "# Optionally, display the predictions in the notebook\n",
    "print(f'Image path: {new_image_path}')\n",
    "#for label, percentage in predictions:\n",
    "#    print(f'Predicted class: {label}, Confidence: {percentage:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
