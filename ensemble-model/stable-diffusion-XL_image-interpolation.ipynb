{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e9a32e47a44fdd97def5af924e85fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading SD 2.1 model:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe35d26133334049af3583dd24e54869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607fc10f226948f6879385f0c5791978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading and preprocessing images:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating between images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b538d6e32b44c6b72e2f27fcf16c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Interpolating and Generating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72daba931d5e400892cfe8e99c71aed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 7.65 GiB of which 98.94 MiB is free. Process 14794 has 256.00 MiB memory in use. Process 19628 has 3.09 GiB memory in use. Including non-PyTorch memory, this process has 2.10 GiB memory in use. Of the allocated memory 1.84 GiB is allocated by PyTorch, and 64.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionImg2ImgPipeline, DDIMScheduler\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "\n",
    "# Parameters\n",
    "model_id = \"stabilityai/stable-diffusion-2-1\"\n",
    "image_paths = [\n",
    "    \"../data/results/ma-boston_200250_fake_B.png\",\n",
    "    \"../data/results/nc-charlotte_200250_fake_B.png\",\n",
    "    \"../data/results/ny-manhattan_200250_fake_B.png\",\n",
    "    \"../data/results/pa-pittsburgh_200250_fake_B.png\"\n",
    "]\n",
    "num_steps = 5\n",
    "inference_steps = 20\n",
    "identifier = f\"sd-2-1_cpu_4-images_{num_steps}-steps_{inference_steps}-inference\"\n",
    "output_dir = os.path.join(\"diffusion-output\", identifier)\n",
    "output_image_size = (384, 384)\n",
    "max_image_dimension = 384\n",
    "\n",
    "# Create a dictionary with all relevant parameters\n",
    "params = {\n",
    "    \"identifier\": identifier,\n",
    "    \"model_id\": model_id,\n",
    "    \"num_steps\": num_steps,\n",
    "    \"inference_steps\": inference_steps,\n",
    "    \"output_image_size\": output_image_size,\n",
    "    \"max_image_dimension\": max_image_dimension\n",
    "}\n",
    "\n",
    "# Save parameters to JSON\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(os.path.join(output_dir, \"parameters.json\"), 'w') as f:\n",
    "    json.dump(params, f, indent=4)\n",
    "\n",
    "# Set device to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.resize(output_image_size, Image.LANCZOS)\n",
    "    return image\n",
    "\n",
    "def slerp_images(image1, image2, alpha):\n",
    "    arr1 = np.array(image1).astype(np.float32) / 255.0\n",
    "    arr2 = np.array(image2).astype(np.float32) / 255.0\n",
    "    \n",
    "    omega = np.arccos(np.clip(np.dot(arr1.flatten(), arr2.flatten()) / \n",
    "                              (np.linalg.norm(arr1) * np.linalg.norm(arr2)), -1, 1))\n",
    "    so = np.sin(omega)\n",
    "    interp = np.sin((1.0-alpha)*omega) / so * arr1 + np.sin(alpha*omega) / so * arr2\n",
    "    \n",
    "    interp = np.clip(interp, 0, 1) * 255\n",
    "    return Image.fromarray(interp.astype(np.uint8))\n",
    "\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "\n",
    "try:\n",
    "    # Load the SD 2.1 pipeline with CPU settings\n",
    "    with tqdm(total=1, desc=\"Loading SD 2.1 model\") as pbar:\n",
    "        scheduler = DDIMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "            model_id,\n",
    "            scheduler=scheduler,\n",
    "            torch_dtype=torch.float32,  # Use float32 for CPU\n",
    "            safety_checker=None,\n",
    "            feature_extractor=None,\n",
    "            requires_safety_checker=False,\n",
    "        )\n",
    "        pipe = pipe.to(device)\n",
    "        clear_memory()\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Load and preprocess images\n",
    "    images = []\n",
    "    with tqdm(total=len(image_paths), desc=\"Loading and preprocessing images\") as pbar:\n",
    "        for image_path in image_paths:\n",
    "            image = load_and_preprocess_image(image_path)\n",
    "            images.append(image)\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Interpolate between images\n",
    "    print(\"Interpolating between images...\")\n",
    "    alphas = np.linspace(0, 1, num_steps)\n",
    "    interpolated_images = []\n",
    "    \n",
    "    with tqdm(total=num_steps, desc=\"Interpolating and Generating\") as pbar:\n",
    "        for alpha in alphas:\n",
    "            # Interpolate between the first and last image\n",
    "            interpolated_image = slerp_images(images[0], images[-1], alpha)\n",
    "            \n",
    "            # Generate image using SD 2.1\n",
    "            with torch.no_grad():\n",
    "                output = pipe(\n",
    "                    prompt=\"A high quality image\",\n",
    "                    image=interpolated_image,\n",
    "                    num_inference_steps=inference_steps,\n",
    "                    guidance_scale=7.5,\n",
    "                    strength=0.5\n",
    "                ).images[0]\n",
    "            \n",
    "            interpolated_images.append(output)\n",
    "            \n",
    "            # Save the interpolated image\n",
    "            output_path = os.path.join(output_dir, f\"interpolated_{len(interpolated_images)}.png\")\n",
    "            output.save(output_path, quality=95)\n",
    "            \n",
    "            clear_memory()\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f\"Interpolation complete. {num_steps} images generated and saved in {output_dir}\")\n",
    "\n",
    "    # Plot results and save the plot as an image file\n",
    "    print(\"Plotting results...\")\n",
    "    fig, axes = plt.subplots(1, num_steps, figsize=(20, 4))\n",
    "    for ax, img in zip(axes, interpolated_images):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plot_path = os.path.join(output_dir, \"interpolation_steps.png\")\n",
    "    fig.savefig(plot_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    clear_memory()\n",
    "    print(f\"Plot saved to {plot_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
