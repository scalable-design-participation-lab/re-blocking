{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet Based City Predictions with Softmax Output for the Building-to-Parcel Workflow\n",
    "# Leonard Schrage, l.schrage@northeastern.edu / lschrage@mit.edu, 2024-25\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration Parameters\n",
    "# =============================================================================\n",
    "\n",
    "# Model Configuration\n",
    "RESNET_MODEL = 'ResNet50'  # Options: 'ResNet18', 'ResNet50'\n",
    "CLASS_NAMES = ['Boston', 'Charlotte', 'Manhattan', 'Pittsburgh']\n",
    "MODEL_PATH = \"models/softmax-ResNet50_50-ep_128-bs_2024-12-06_10-33.pth\"\n",
    "\n",
    "# Input/Output Configuration\n",
    "TEST_FOLDERS = {\n",
    "    'brooklyn': \"/home/ls/sites/re-blocking/image-generation/brooklyn_comparison/parcels\"\n",
    "}\n",
    "\n",
    "# Verify paths exist\n",
    "valid_folders = {}\n",
    "for name, path in TEST_FOLDERS.items():\n",
    "    if os.path.exists(path):\n",
    "        print(f\"Found valid path: {path}\")\n",
    "        valid_folders[name] = path\n",
    "    else:\n",
    "        print(f\"Path not found: {path}\")\n",
    "TEST_FOLDERS = valid_folders\n",
    "\n",
    "SAMPLE_SIZE = None  # Number of images to process per folder (None for all images)\n",
    "OUTPUT_DIR = \"softmax-output/city-predictions\"  # Base directory for saving results\n",
    "\n",
    "# Files to ignore (Mac and hidden files)\n",
    "IGNORE_PATTERNS = {\n",
    "    '.DS_Store',\n",
    "    '._',\n",
    "    '.AppleDouble',\n",
    "    '.LSOverride',\n",
    "    'Icon\\r',\n",
    "    '.Spotlight-V100',\n",
    "    '.Trashes',\n",
    "    '__MACOSX',\n",
    "    'thumbs.db',\n",
    "    'Thumbs.db',\n",
    "    '.git',\n",
    "    '.ipynb_checkpoints'\n",
    "}\n",
    "\n",
    "# Model Parameters\n",
    "NUM_AUGMENTATIONS = 5  # Number of augmentations for test-time augmentation\n",
    "TEMPERATURE = 1.5  # Temperature scaling for prediction sharpening\n",
    "IMG_SIZE = 224  # Input image size\n",
    "NORMALIZE_MEAN = [0.485, 0.456, 0.406]  \n",
    "NORMALIZE_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Augmentation Parameters\n",
    "ROTATION_DEGREES = 10  # Max rotation degrees for augmentation\n",
    "BRIGHTNESS_JITTER = 0.1  # Brightness adjustment range\n",
    "TRANSLATION_RANGE = 0.05  # Max translation as fraction of image size\n",
    "\n",
    "# Visualization Parameters\n",
    "CONFIDENCE_BINS = 30  # Number of bins for confidence histogram\n",
    "PLOT_SIZE_LARGE = (12, 6)  # Size for large plots\n",
    "PLOT_SIZE_MEDIUM = (10, 6)  # Size for medium plots\n",
    "\n",
    "# =============================================================================\n",
    "# Model Setup\n",
    "# =============================================================================\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \n",
    "                     \"mps\" if torch.backends.mps.is_available() else \n",
    "                     \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Transform for prediction\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD),\n",
    "])\n",
    "\n",
    "def is_valid_image_file(file_path):\n",
    "    \"\"\"Check if a file is a valid image and not a system or hidden file\"\"\"\n",
    "    file_name = file_path.name\n",
    "    \n",
    "    # Check for ignored patterns\n",
    "    if any(pattern in str(file_path) for pattern in IGNORE_PATTERNS):\n",
    "        return False\n",
    "    \n",
    "    # Check if it's a hidden file\n",
    "    if file_name.startswith('.') or file_name.startswith('_'):\n",
    "        return False\n",
    "        \n",
    "    # Verify it's a valid image\n",
    "    try:\n",
    "        with Image.open(file_path) as img:\n",
    "            img.verify()\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load the trained model with the improved architecture\"\"\"\n",
    "    try:\n",
    "        if RESNET_MODEL == 'ResNet18':\n",
    "            weights = models.ResNet18_Weights.DEFAULT\n",
    "            model = models.resnet18(weights=weights)\n",
    "        elif RESNET_MODEL == 'ResNet50':\n",
    "            weights = models.ResNet50_Weights.DEFAULT\n",
    "            model = models.resnet50(weights=weights)\n",
    "        \n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(model.fc.in_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, len(CLASS_NAMES))\n",
    "        )\n",
    "        \n",
    "        checkpoint = torch.load(model_path, map_location=device, weights_only=True)\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "        \n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def predict_single_pass(model, image_tensor):\n",
    "    \"\"\"Make a single prediction pass\"\"\"\n",
    "    outputs = model(image_tensor)\n",
    "    scaled_outputs = outputs / TEMPERATURE\n",
    "    probabilities = F.softmax(scaled_outputs, dim=1)[0]\n",
    "    return probabilities\n",
    "\n",
    "def predict_with_tta(model, image_path, num_augmentations=NUM_AUGMENTATIONS):\n",
    "    \"\"\"Predict with Test Time Augmentation\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Base prediction\n",
    "            base_tensor = transform(image).unsqueeze(0).to(device)\n",
    "            base_pred = predict_single_pass(model, base_tensor)\n",
    "            predictions.append(base_pred)\n",
    "            \n",
    "            # TTA predictions\n",
    "            tta_transforms = [\n",
    "                transforms.RandomHorizontalFlip(p=1.0),\n",
    "                transforms.RandomRotation(ROTATION_DEGREES),\n",
    "                transforms.ColorJitter(brightness=BRIGHTNESS_JITTER),\n",
    "                transforms.RandomAffine(ROTATION_DEGREES, translate=(TRANSLATION_RANGE, TRANSLATION_RANGE)),\n",
    "            ]\n",
    "            \n",
    "            for _ in range(num_augmentations):\n",
    "                aug_tensor = base_tensor.clone()\n",
    "                for t in random.sample(tta_transforms, 2):\n",
    "                    aug_tensor = t(aug_tensor)\n",
    "                aug_pred = predict_single_pass(model, aug_tensor)\n",
    "                predictions.append(aug_pred)\n",
    "            \n",
    "            final_pred = torch.mean(torch.stack(predictions), dim=0)\n",
    "            predicted_class = torch.argmax(final_pred).item()\n",
    "            confidence = float(final_pred[predicted_class])\n",
    "            \n",
    "            return final_pred.cpu().numpy(), predicted_class, confidence\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting image {image_path}: {str(e)}\")\n",
    "        return None, None, None\n",
    "    \n",
    "def analyze_results(results):\n",
    "    \"\"\"Analyze prediction results and generate statistics\"\"\"\n",
    "    if not results:\n",
    "        return {\n",
    "            'confidence_stats': {},\n",
    "            'class_distribution': {},\n",
    "            'probability_stats': {}\n",
    "        }\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Calculate confidence statistics\n",
    "    confidence_stats = {\n",
    "        'mean_confidence': df['confidence'].mean(),\n",
    "        'median_confidence': df['confidence'].median(),\n",
    "        'min_confidence': df['confidence'].min(),\n",
    "        'max_confidence': df['confidence'].max(),\n",
    "        'std_confidence': df['confidence'].std()\n",
    "    }\n",
    "    \n",
    "    # Calculate class distribution\n",
    "    class_distribution = df['predicted_class'].value_counts().to_dict()\n",
    "    \n",
    "    # Calculate probability statistics per class\n",
    "    prob_stats = {}\n",
    "    for class_name in CLASS_NAMES:\n",
    "        probs = [r['probabilities'][class_name] for r in results]\n",
    "        prob_stats[class_name] = {\n",
    "            'mean': np.mean(probs),\n",
    "            'median': np.median(probs),\n",
    "            'min': np.min(probs),\n",
    "            'max': np.max(probs),\n",
    "            'std': np.std(probs)\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'confidence_stats': confidence_stats,\n",
    "        'class_distribution': class_distribution,\n",
    "        'probability_stats': prob_stats\n",
    "    }\n",
    "\n",
    "def generate_visualizations(results, output_dir):\n",
    "    \"\"\"Generate and save visualization plots\"\"\"\n",
    "    if not results:\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # 1. Confidence Distribution\n",
    "    plt.figure(figsize=PLOT_SIZE_MEDIUM)\n",
    "    sns.histplot(data=df, x='confidence', bins=CONFIDENCE_BINS)\n",
    "    plt.title('Distribution of Prediction Confidence')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig(os.path.join(output_dir, 'confidence_distribution.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Class Distribution\n",
    "    plt.figure(figsize=PLOT_SIZE_MEDIUM)\n",
    "    sns.countplot(data=df, x='predicted_class')\n",
    "    plt.title('Distribution of Predicted Classes')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'class_distribution.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Probability Distribution by Class\n",
    "    prob_data = []\n",
    "    for result in results:\n",
    "        for class_name, prob in result['probabilities'].items():\n",
    "            prob_data.append({\n",
    "                'class': class_name,\n",
    "                'probability': prob\n",
    "            })\n",
    "    \n",
    "    prob_df = pd.DataFrame(prob_data)\n",
    "    plt.figure(figsize=PLOT_SIZE_LARGE)\n",
    "    sns.boxplot(data=prob_df, x='class', y='probability')\n",
    "    plt.title('Probability Distribution by Class')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'probability_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "def generate_comparative_analysis(all_results, base_output_dir):\n",
    "    \"\"\"Generate comparative visualizations and reports across folders\"\"\"\n",
    "    comparative_dir = base_output_dir / 'comparative_analysis'\n",
    "    comparative_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Collect data for comparison\n",
    "    comparison_data = {\n",
    "        'confidence': [],\n",
    "        'class_distribution': [],\n",
    "        'probability_distribution': []\n",
    "    }\n",
    "    \n",
    "    # Process each folder's results\n",
    "    for folder_name, results in all_results.items():\n",
    "        # Confidence stats\n",
    "        confidence_stats = results['analysis']['confidence_stats']\n",
    "        comparison_data['confidence'].append({\n",
    "            'folder': folder_name,\n",
    "            'mean': confidence_stats['mean_confidence'],\n",
    "            'median': confidence_stats['median_confidence'],\n",
    "            'std': confidence_stats['std_confidence']\n",
    "        })\n",
    "        \n",
    "        # Class distribution\n",
    "        class_dist = results['analysis']['class_distribution']\n",
    "        for class_name in CLASS_NAMES:\n",
    "            comparison_data['class_distribution'].append({\n",
    "                'folder': folder_name,\n",
    "                'class': class_name,\n",
    "                'count': class_dist.get(class_name, 0)\n",
    "            })\n",
    "        \n",
    "        # Probability distributions\n",
    "        for pred in results['predictions']:\n",
    "            for class_name, prob in pred['probabilities'].items():\n",
    "                comparison_data['probability_distribution'].append({\n",
    "                    'folder': folder_name,\n",
    "                    'class': class_name,\n",
    "                    'probability': prob\n",
    "                })\n",
    "    \n",
    "    # Create DataFrames\n",
    "    confidence_df = pd.DataFrame(comparison_data['confidence'])\n",
    "    class_dist_df = pd.DataFrame(comparison_data['class_distribution'])\n",
    "    prob_dist_df = pd.DataFrame(comparison_data['probability_distribution'])\n",
    "    \n",
    "    # 1. Confidence Comparison\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    confidence_summary = confidence_df.melt(\n",
    "        id_vars=['folder'], \n",
    "        value_vars=['mean', 'median', 'std'],\n",
    "        var_name='metric'\n",
    "    )\n",
    "    g = sns.barplot(data=confidence_summary, x='folder', y='value', hue='metric')\n",
    "    plt.title('Confidence Metrics Comparison Across Folders')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Metric', bbox_to_anchor=(1.05, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(comparative_dir / 'confidence_comparison.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Class Distribution Comparison\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    pivot_dist = class_dist_df.pivot(index='folder', columns='class', values='count')\n",
    "    ax = pivot_dist.plot(kind='bar', stacked=True)\n",
    "    plt.title('Class Distribution Comparison Across Folders')\n",
    "    plt.xlabel('Folder')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.legend(title='Predicted Class', bbox_to_anchor=(1.05, 1))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(comparative_dir / 'class_distribution_comparison.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Probability Distribution Heatmap\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    pivot_prob = prob_dist_df.groupby(['folder', 'class'])['probability'].mean().unstack()\n",
    "    sns.heatmap(pivot_prob, annot=True, fmt='.2f', cmap='YlOrRd', cbar_kws={'label': 'Mean Probability'})\n",
    "    plt.title('Mean Prediction Probability Heatmap')\n",
    "    plt.ylabel('Folder')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(comparative_dir / 'probability_heatmap.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Generate comparative report\n",
    "    comparative_report = {\n",
    "        'confidence_summary': {\n",
    "            folder: {\n",
    "                'mean': float(stats['mean']),\n",
    "                'median': float(stats['median']),\n",
    "                'std': float(stats['std'])\n",
    "            }\n",
    "            for folder, stats in confidence_df.set_index('folder').to_dict('index').items()\n",
    "        },\n",
    "        'class_distribution': pivot_dist.to_dict('index'),\n",
    "        'probability_matrix': pivot_prob.round(3).to_dict('index'),\n",
    "        'relative_metrics': {\n",
    "            'highest_confidence_folder': confidence_df.loc[confidence_df['mean'].idxmax(), 'folder'],\n",
    "            'most_diverse_predictions': class_dist_df.groupby('folder')['count'].std().idxmin(),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save comparative report\n",
    "    with open(comparative_dir / 'comparative_report.json', 'w') as f:\n",
    "        json.dump(comparative_report, f, indent=4)\n",
    "    \n",
    "    return comparative_report\n",
    "\n",
    "# Main execution code to process images and generate predictions\n",
    "def process_folder(folder_name, folder_path, model, sample_size=SAMPLE_SIZE):\n",
    "    \"\"\"Process all images in a folder and generate predictions\"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    print(f\"Processing folder: {folder_name} ({folder_path})\")\n",
    "    \n",
    "    # Find all valid image files\n",
    "    image_files = []\n",
    "    for file_path in folder_path.glob('**/*'):\n",
    "        if file_path.is_file() and file_path.suffix.lower() in ['.jpg', '.jpeg', '.png'] and is_valid_image_file(file_path):\n",
    "            image_files.append(file_path)\n",
    "    \n",
    "    # Sample if needed\n",
    "    if sample_size and len(image_files) > sample_size:\n",
    "        image_files = random.sample(image_files, sample_size)\n",
    "    \n",
    "    print(f\"Found {len(image_files)} valid images to process\")\n",
    "    \n",
    "    # Process images\n",
    "    results = []\n",
    "    for img_path in tqdm(image_files, desc=f\"Predicting {folder_name}\"):\n",
    "        probs, class_idx, confidence = predict_with_tta(model, img_path)\n",
    "        \n",
    "        if probs is not None:\n",
    "            result = {\n",
    "                'image_path': str(img_path),\n",
    "                'predicted_class': CLASS_NAMES[class_idx],\n",
    "                'confidence': confidence,\n",
    "                'probabilities': {class_name: float(prob) for class_name, prob in zip(CLASS_NAMES, probs)}\n",
    "            }\n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Set up output directory\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = output_dir / f\"run_{timestamp}\"\n",
    "run_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Load model once\n",
    "print(\"Loading model...\")\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# Process each folder\n",
    "all_results = {}\n",
    "for folder_name, folder_path in TEST_FOLDERS.items():\n",
    "    folder_output_dir = run_dir / folder_name\n",
    "    folder_output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Process images\n",
    "    predictions = process_folder(folder_name, folder_path, model)\n",
    "    \n",
    "    # Analyze results\n",
    "    analysis = analyze_results(predictions)\n",
    "    \n",
    "    # Generate visualizations\n",
    "    generate_visualizations(predictions, folder_output_dir)\n",
    "    \n",
    "    # Save predictions to JSON\n",
    "    with open(folder_output_dir / 'predictions.json', 'w') as f:\n",
    "        json.dump(predictions, f, indent=4)\n",
    "    \n",
    "    # Save analysis to JSON\n",
    "    with open(folder_output_dir / 'analysis.json', 'w') as f:\n",
    "        json.dump(analysis, f, indent=4)\n",
    "    \n",
    "    # Store results for comparative analysis\n",
    "    all_results[folder_name] = {\n",
    "        'predictions': predictions,\n",
    "        'analysis': analysis\n",
    "    }\n",
    "    \n",
    "    print(f\"Processed {len(predictions)} images from {folder_name}\")\n",
    "    print(f\"Class distribution: {analysis['class_distribution']}\")\n",
    "    print(f\"Mean confidence: {analysis['confidence_stats']['mean_confidence']:.4f}\")\n",
    "\n",
    "# Generate comparative analysis if multiple folders were processed\n",
    "if len(all_results) > 1:\n",
    "    comparative_report = generate_comparative_analysis(all_results, run_dir)\n",
    "    print(\"Generated comparative analysis across all folders\")\n",
    "\n",
    "print(f\"All processing complete. Results saved to {run_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
