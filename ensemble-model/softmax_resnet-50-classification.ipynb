{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image, ImageFile\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy.stats import linregress\n",
    "import requests\n",
    "import tempfile\n",
    "import gc\n",
    "import contextlib\n",
    "\n",
    "# Parameters\n",
    "identifier = 'softmax-v28-prevent-overfitting'\n",
    "class_names = ['Boston', 'Charlotte', 'Manhattan', 'Pittsburgh']\n",
    "base_folder = '../data'\n",
    "folders = {\n",
    "    'Boston': os.path.join(base_folder, 'ma-boston'),\n",
    "    'Charlotte': os.path.join(base_folder, 'nc-charlotte'),\n",
    "    'Manhattan': os.path.join(base_folder, 'ny-manhattan'),\n",
    "    'Pittsburgh': os.path.join(base_folder, 'pa-pittsburgh')\n",
    "}\n",
    "output_folder = 'softmax-output'\n",
    "normalize_mean = [0.485, 0.456, 0.406]\n",
    "normalize_std = [0.229, 0.224, 0.225]\n",
    "batch_size = 32\n",
    "num_classes = len(class_names)\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "checkpoint_interval = 5\n",
    "checkpoint_dir = os.path.join(output_folder, f'checkpoints-{identifier}')\n",
    "model_save_path = os.path.join(output_folder, f'trained-model-{identifier}.pth')\n",
    "loss_log_path = os.path.join(output_folder, f'loss-log-{identifier}.json')\n",
    "new_image_path = os.path.join(base_folder, 'ny-brooklyn', 'buildings_1370.jpg')\n",
    "predictions_output_file = os.path.join(output_folder, f'predictions-{identifier}.txt')\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def download_file_with_progress(url, filename):\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 KB\n",
    "    with open(filename, 'wb') as file, tqdm(\n",
    "        desc=filename,\n",
    "        total=total_size,\n",
    "        unit='iB',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(block_size):\n",
    "            size = file.write(data)\n",
    "            progress_bar.update(size)\n",
    "\n",
    "def download_pretrained_weights():\n",
    "    print(\"Downloading pre-trained weights...\")\n",
    "    url = \"https://download.pytorch.org/models/resnet18-5c106cde.pth\"\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "        download_file_with_progress(url, temp_file.name)\n",
    "        state_dict = torch.load(temp_file.name, map_location='cpu')\n",
    "    os.unlink(temp_file.name)\n",
    "    return state_dict\n",
    "\n",
    "# Download weights\n",
    "pretrained_weights = download_pretrained_weights()\n",
    "\n",
    "print(\"Setup completed. Pre-trained weights downloaded and ready for use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image, ImageFile\n",
    "from tqdm.auto import tqdm\n",
    "import contextlib\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "print(\"Defining data transformations...\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normalize_mean, std=normalize_std)\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            with open(image_path, 'rb') as f:\n",
    "                img = Image.open(f).convert('RGB')\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {str(e)}\")\n",
    "            return torch.zeros((3, 224, 224)), label\n",
    "\n",
    "print(\"Preparing dataset...\")\n",
    "all_image_paths = []\n",
    "all_labels = []\n",
    "class_to_idx = {}\n",
    "skipped_files = []\n",
    "\n",
    "with contextlib.closing(tqdm(folders.items(), desc=\"Loading class folders\")) as pbar:\n",
    "    for class_name, folder in pbar:\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"Warning: Folder not found: {folder}\")\n",
    "            continue\n",
    "        class_idx = len(class_to_idx)\n",
    "        class_to_idx[class_name] = class_idx\n",
    "        for img_name in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, img_name)\n",
    "            if os.path.isfile(img_path):\n",
    "                all_image_paths.append(img_path)\n",
    "                all_labels.append(class_idx)\n",
    "\n",
    "print(f\"Dataset prepared with {len(all_image_paths)} images\")\n",
    "\n",
    "print(\"Creating dataset...\")\n",
    "full_dataset = CustomDataset(all_image_paths, all_labels, transform=transform)\n",
    "\n",
    "print(\"Splitting dataset into train and test sets...\")\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Creating DataLoaders...\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained_weights):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=None)\n",
    "        self.resnet.load_state_dict(pretrained_weights)\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "print(\"Initializing the model...\")\n",
    "model = CustomResNet18(len(class_to_idx), pretrained_weights).to(device)\n",
    "\n",
    "print(f\"Dataset created with {len(full_dataset)} images\")\n",
    "print(f\"Training set: {len(train_dataset)} images\")\n",
    "print(f\"Test set: {len(test_dataset)} images\")\n",
    "print(f\"Model initialized and moved to device: {device}\")\n",
    "print(f\"Train DataLoader created with {len(train_loader)} batches\")\n",
    "print(f\"Test DataLoader created with {len(test_loader)} batches\")\n",
    "\n",
    "# Export skipped files list\n",
    "skipped_files_path = os.path.join(output_folder, f'skipped_files-{identifier}.txt')\n",
    "with open(skipped_files_path, 'w') as f:\n",
    "    for path, reason in skipped_files:\n",
    "        f.write(f\"{path}: {reason}\\n\")\n",
    "print(f\"List of skipped files exported to: {skipped_files_path}\")\n",
    "\n",
    "print(\"Clearing memory...\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "\n",
    "print(\"Section 2 completed successfully\")\n",
    "\n",
    "print(\"Testing data loading...\")\n",
    "with contextlib.closing(tqdm(train_loader, desc=\"Testing batches\", total=min(5, len(train_loader)))) as pbar:\n",
    "    for i, (images, labels) in enumerate(pbar):\n",
    "        if i == 4:  # Test first 5 batches\n",
    "            break\n",
    "print(\"Data loading test completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_early_stopping(model, train_loader, val_loader, num_epochs, patience=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    train_loss_log, val_loss_log, val_accuracy_log = [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total_samples = 0\n",
    "        with contextlib.closing(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")) as pbar:\n",
    "            for images, labels in pbar:\n",
    "                if images.numel() == 0:\n",
    "                    continue\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item() * images.size(0)\n",
    "                total_samples += images.size(0)\n",
    "                pbar.set_postfix({'train_loss': loss.item()})\n",
    "        \n",
    "        train_loss /= total_samples\n",
    "        train_loss_log.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            with contextlib.closing(tqdm(val_loader, desc=\"Validating\", leave=False)) as pbar:\n",
    "                for images, labels in pbar:\n",
    "                    if images.numel() == 0:\n",
    "                        continue\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    pbar.set_postfix({'val_loss': loss.item()})\n",
    "\n",
    "        val_loss /= total\n",
    "        val_accuracy = correct / total if total > 0 else 0\n",
    "        val_loss_log.append(val_loss)\n",
    "        val_accuracy_log.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f'Early stopping triggered after epoch {epoch+1}')\n",
    "                model.load_state_dict(torch.load(model_save_path))\n",
    "                break\n",
    "\n",
    "    # Save the loss and accuracy logs\n",
    "    with open(loss_log_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'train_loss': train_loss_log,\n",
    "            'val_loss': val_loss_log,\n",
    "            'val_accuracy': val_accuracy_log\n",
    "        }, f)\n",
    "\n",
    "    # Plot the loss and accuracy curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss_log, label='Train Loss')\n",
    "    plt.plot(val_loss_log, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracy_log)\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f'training_curves-{identifier}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    return val_accuracy_log[-1]\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(num_classes))\n",
    "    class_total = list(0. for i in range(num_classes))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with contextlib.closing(tqdm(data_loader, desc=\"Evaluating\")) as pbar:\n",
    "            for images, labels in pbar:\n",
    "                if images.numel() == 0:\n",
    "                    continue\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                c = (predicted == labels).squeeze()\n",
    "                for i in range(len(labels)):\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    print(f'Overall accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        class_accuracy = 100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0\n",
    "        print(f'Accuracy of {class_names[i]}: {class_accuracy:.2f}%')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cross_validation(fold_results):\n",
    "    avg_accuracy = np.mean(fold_results)\n",
    "    std_accuracy = np.std(fold_results)\n",
    "    \n",
    "    print(f\"Cross-validation results:\")\n",
    "    print(f\"Average accuracy: {avg_accuracy:.4f}\")\n",
    "    print(f\"Standard deviation: {std_accuracy:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(1, len(fold_results) + 1), fold_results)\n",
    "    plt.axhline(y=avg_accuracy, color='r', linestyle='--', label='Average')\n",
    "    plt.title('Cross-validation Accuracy per Fold')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_folder, f'cross_validation_results-{identifier}.png'))\n",
    "    plt.close()\n",
    "\n",
    "def error_analysis(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    misclassified_images = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with contextlib.closing(tqdm(test_loader, desc=\"Analyzing errors\")) as pbar:\n",
    "            for images, labels in pbar:\n",
    "                if images.numel() == 0:\n",
    "                    continue\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                misclassified = (preds != labels).nonzero().squeeze()\n",
    "                for idx in misclassified:\n",
    "                    misclassified_images.append((images[idx].cpu(), labels[idx].item(), preds[idx].item()))\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig(os.path.join(output_folder, f'confusion_matrix-{identifier}.png'))\n",
    "    plt.close()\n",
    "\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(misclassified_images):\n",
    "            img, true_label, pred_label = misclassified_images[i]\n",
    "            ax.imshow(img.permute(1, 2, 0))\n",
    "            ax.set_title(f'True: {class_names[true_label]}\\nPred: {class_names[pred_label]}')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f'misclassified_samples-{identifier}.png'))\n",
    "    plt.close()\n",
    "\n",
    "def compare_with_baseline(train_data, test_data, model_accuracy):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for images, labels in tqdm(train_data, desc=\"Preparing train data\"):\n",
    "        if images.numel() > 0:\n",
    "            X_train.append(images.view(images.size(0), -1).cpu().numpy())\n",
    "            y_train.append(labels.cpu().numpy())\n",
    "    \n",
    "    for images, labels in tqdm(test_data, desc=\"Preparing test data\"):\n",
    "        if images.numel() > 0:\n",
    "            X_test.append(images.view(images.size(0), -1).cpu().numpy())\n",
    "            y_test.append(labels.cpu().numpy())\n",
    "\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    X_test = np.concatenate(X_test)\n",
    "    y_test = np.concatenate(y_test)\n",
    "\n",
    "    print(f\"Train data shape: {X_train.shape}, Train labels shape: {y_train.shape}\")\n",
    "    print(f\"Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}\")\n",
    "\n",
    "    baseline_model = DummyClassifier(strategy='stratified')\n",
    "    baseline_model.fit(X_train, y_train)\n",
    "    baseline_preds = baseline_model.predict(X_test)\n",
    "    baseline_accuracy = accuracy_score(y_test, baseline_preds) * 100\n",
    "\n",
    "    print(f\"Baseline model accuracy: {baseline_accuracy:.2f}%\")\n",
    "    print(f\"Improvement over baseline: {model_accuracy - baseline_accuracy:.2f}%\")\n",
    "\n",
    "def predict_image(model, image_path, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = F.softmax(outputs, dim=1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return probabilities.cpu().numpy(), predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Train the model\n",
    "        print(\"Training the model...\")\n",
    "        final_accuracy = train_with_early_stopping(model, train_loader, test_loader, num_epochs)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        print(\"Evaluating on test set...\")\n",
    "        test_accuracy = evaluate_model(model, test_loader)\n",
    "        \n",
    "        # Perform error analysis\n",
    "        print(\"Performing error analysis...\")\n",
    "        error_analysis(model, test_loader)\n",
    "        \n",
    "        # Compare with baseline\n",
    "        print(\"Comparing with baseline model...\")\n",
    "        compare_with_baseline(train_loader, test_loader, test_accuracy)\n",
    "        \n",
    "        # Predict on a new image\n",
    "        print(f\"Predicting on new image: {new_image_path}\")\n",
    "        new_image_probabilities, new_image_class = predict_image(model, new_image_path, transform)\n",
    "        \n",
    "        # Print and save predictions\n",
    "        predictions = [f\"{class_names[i]}: {prob:.2f}\" for i, prob in enumerate(new_image_probabilities)]\n",
    "        print(f\"Predictions for {new_image_path}:\")\n",
    "        print(f\"Predicted class: {class_names[new_image_class]}\")\n",
    "        print(\"Class probabilities:\")\n",
    "        for pred in predictions:\n",
    "            print(pred)\n",
    "        \n",
    "        with open(predictions_output_file, 'w') as f:\n",
    "            f.write(f\"Predictions for {new_image_path}:\\n\")\n",
    "            f.write(f\"Predicted class: {class_names[new_image_class]}\\n\")\n",
    "            f.write(\"Class probabilities:\\n\")\n",
    "            for pred in predictions:\n",
    "                f.write(f\"{pred}\\n\")\n",
    "        \n",
    "        print(f\"Predictions saved to {predictions_output_file}\")\n",
    "        print(\"Script execution completed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during execution: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "    finally:\n",
    "        # Clear memory\n",
    "        print(\"Clearing memory...\")\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
