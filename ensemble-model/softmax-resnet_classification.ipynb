{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training parameters saved to softmax-output/softmax-ResNet50_100-ep_32-bs_25000-images_2024-10-14_16-34/training-params_softmax-ResNet50_100-ep_32-bs_25000-images_2024-10-14_16-34.json\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 42/208400 [00:14<19:28:59,  2.97it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image, ImageFile, UnidentifiedImageError\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Parameters to tweak\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 100\n",
    "checkpoint_interval = 25\n",
    "max_images_per_class = 25000 # limit dataset size (we have 25k per class), go higher with bigger ResNet model\n",
    "resnet_model = 'ResNet50'  # ResNet18 or 50 (add 34, 101?)\n",
    "\n",
    "# Directories\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "identifier = f\"softmax-{resnet_model}_{num_epochs}-ep_{batch_size}-bs_{max_images_per_class}-images_{current_time}\"\n",
    "class_names = ['Boston', 'Charlotte', 'Manhattan', 'Pittsburgh']\n",
    "folders = {\n",
    "    'Boston': '../data/ma-boston/buildings',\n",
    "    'Charlotte': '../data/nc-charlotte/buildings',\n",
    "    'Manhattan': '../data/ny-manhattan/buildings',\n",
    "    'Pittsburgh': '../data/pa-pittsburgh/buildings'\n",
    "}\n",
    "output_folder = os.path.join('softmax-output', identifier)\n",
    "checkpoint_dir = os.path.join(output_folder, 'checkpoints')\n",
    "model_save_path = os.path.join(output_folder, f'trained-model_{identifier}.pth')\n",
    "loss_log_path = os.path.join(output_folder, f'loss-log_{identifier}.json')\n",
    "training_curves_path = os.path.join(output_folder, f'training-curves_{identifier}.png')\n",
    "confusion_matrix_path = os.path.join(output_folder, f'confusion-matrix_{identifier}.png')\n",
    "cross_validation_path = os.path.join(output_folder, f'cross-validation_{identifier}.png')\n",
    "misclassified_samples_path = os.path.join(output_folder, f'misclassified-samples_{identifier}.png')\n",
    "report_path = os.path.join(output_folder, f'report_{identifier}.txt')\n",
    "new_image_path = '../data/ny-brooklyn/buildings/buildings_1370.jpg'\n",
    "predictions_output_file = os.path.join(output_folder, f'predictions_{identifier}.txt')\n",
    "\n",
    "# More Parameters\n",
    "normalize_mean = [0.485, 0.456, 0.406] # mean pixel values of the ImageNet dataset\n",
    "normalize_std = [0.229, 0.224, 0.225] # standard deviation of pixel values in the ImageNet dataset\n",
    "num_classes = len(class_names)\n",
    "weight_decay = 1e-4 # Changed from 1e-3 to 1e-4 for regularization\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Define output folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CityDataset(Dataset):\n",
    "    def __init__(self, folders, transform=None, max_images_per_class=max_images_per_class):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(folders.keys())}\n",
    "\n",
    "        for class_name, folder in folders.items():\n",
    "            class_images = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            selected_images = random.sample(class_images, min(max_images_per_class, len(class_images)))\n",
    "            self.image_paths.extend(selected_images)\n",
    "            self.labels.extend([self.class_to_idx[class_name]] * len(selected_images))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        while True:\n",
    "            image_path = self.image_paths[idx]\n",
    "            label = self.labels[idx]\n",
    "            try:\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return image, label\n",
    "            except (UnidentifiedImageError, OSError) as e:\n",
    "                print(f\"Skipping corrupted image: {image_path}\")\n",
    "                idx = (idx + 1) % len(self.image_paths)\n",
    "\n",
    "# Define transformations with data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=normalize_mean, std=normalize_std),\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = CityDataset(folders, transform=transform)\n",
    "\n",
    "# Set device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load a pre-trained ResNet model based on the parameter\n",
    "if resnet_model == 'ResNet18':\n",
    "    weights = models.ResNet18_Weights.DEFAULT\n",
    "    model = models.resnet18(weights=weights)\n",
    "elif resnet_model == 'ResNet50':\n",
    "    weights = models.ResNet50_Weights.DEFAULT\n",
    "    model = models.resnet50(weights=weights)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported ResNet model: {resnet_model}\")\n",
    "\n",
    "# Modify the final layer to match the number of classes\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(model.fc.in_features, num_classes)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Save training parameters\n",
    "training_params = {\n",
    "    \"identifier\": identifier,\n",
    "    \"model\": resnet_model,\n",
    "    \"device\": str(device).split(':')[0],\n",
    "    \"max_images_per_class\": max_images_per_class,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"class_names\": class_names,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"checkpoint_interval\": checkpoint_interval,\n",
    "    \"normalize_mean\": normalize_mean,\n",
    "    \"normalize_std\": normalize_std\n",
    "}\n",
    "params_path = os.path.join(output_folder, f'training-params_{identifier}.json')\n",
    "with open(params_path, 'w') as f:\n",
    "    json.dump(training_params, f, indent=4)  # Add indent parameter for readability\n",
    "print(f\"Training parameters saved to {params_path}\")\n",
    "\n",
    "# Model training function\n",
    "def train_and_save_model(model, train_loader, val_loader, num_epochs, checkpoint_interval, checkpoint_dir):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "    val_accuracy_log = []\n",
    "    epoch_times = []\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    total_iterations = num_epochs * len(train_loader)\n",
    "    progress_bar = tqdm(total=total_iterations, desc=\"Training Progress\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_loss_log.append(epoch_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "        val_accuracy = correct / total\n",
    "        val_loss_log.append(val_epoch_loss)\n",
    "        val_accuracy_log.append(val_accuracy)\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_epoch_loss)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_epoch_loss < best_val_loss:\n",
    "            best_val_loss = val_epoch_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - epoch_start_time\n",
    "        epoch_times.append(epoch_duration)\n",
    "\n",
    "        progress_bar.set_postfix({\n",
    "            'Epoch': f'{epoch + 1}/{num_epochs}',\n",
    "            'Train Loss': f'{epoch_loss:.4f}',\n",
    "            'Val Loss': f'{val_epoch_loss:.4f}',\n",
    "            'Val Accuracy': f'{val_accuracy:.4f}',\n",
    "            'Epoch Time (s)': f'{epoch_duration:.2f}'\n",
    "        })\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % checkpoint_interval == 0:\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + 1}.pth')\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Save the final model weights\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "    # Save the loss and accuracy logs\n",
    "    with open(loss_log_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'train_loss': train_loss_log,\n",
    "            'val_loss': val_loss_log,\n",
    "            'val_accuracy': val_accuracy_log,\n",
    "            'epoch_times': epoch_times\n",
    "        }, f)\n",
    "\n",
    "    # Plot the loss and accuracy curves\n",
    "    plot_training_curves(train_loss_log, val_loss_log, val_accuracy_log)\n",
    "\n",
    "    return train_loss_log, val_loss_log, val_accuracy_log\n",
    "\n",
    "def plot_training_curves(train_loss_log, val_loss_log, val_accuracy_log):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(train_loss_log) + 1), train_loss_log, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_loss_log) + 1), val_loss_log, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(val_accuracy_log) + 1), val_accuracy_log)\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(training_curves_path)\n",
    "    plt.close()\n",
    "\n",
    "def k_fold_cross_validation(dataset, num_folds=3):\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    fold_times = []\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_train_loss_logs = []\n",
    "    all_val_loss_logs = []\n",
    "    all_val_accuracy_logs = []\n",
    "\n",
    "    for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset), 1):\n",
    "        print(f\"Fold {fold}\")\n",
    "        fold_start_time = time.time()\n",
    "        \n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "        \n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "        val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_subsampler)\n",
    "        \n",
    "        if resnet_model == 'ResNet18':\n",
    "            model = models.resnet18(weights=weights)\n",
    "        elif resnet_model == 'ResNet50':\n",
    "            model = models.resnet50(weights=weights)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported ResNet model: {resnet_model}\")\n",
    "        \n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(model.fc.in_features, num_classes)\n",
    "        )\n",
    "        model.to(device)\n",
    "        \n",
    "        train_loss_log, val_loss_log, val_accuracy_log = train_and_save_model(\n",
    "            model, train_loader, val_loader, num_epochs, checkpoint_interval, \n",
    "            os.path.join(checkpoint_dir, f'fold_{fold}')\n",
    "        )\n",
    "        \n",
    "        all_train_loss_logs.append(train_loss_log)\n",
    "        all_val_loss_logs.append(val_loss_log)\n",
    "        all_val_accuracy_logs.append(val_accuracy_log)\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        fold_labels = []\n",
    "        fold_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                fold_labels.extend(labels.cpu().numpy())\n",
    "                fold_predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        fold_results.append(accuracy)\n",
    "        all_labels.extend(fold_labels)\n",
    "        all_predictions.extend(fold_predictions)\n",
    "        fold_end_time = time.time()\n",
    "        fold_duration = fold_end_time - fold_start_time\n",
    "        fold_times.append(fold_duration)\n",
    "        print(f\"Fold {fold} accuracy: {accuracy:.4f}, Time: {fold_duration:.2f} seconds\")\n",
    "    \n",
    "    average_accuracy = sum(fold_results) / len(fold_results)\n",
    "    print(f\"Average accuracy across folds: {average_accuracy:.4f}\")\n",
    "    print(f\"Average time per fold: {sum(fold_times) / len(fold_times):.2f} seconds\")\n",
    "\n",
    "    # Plot cross-validation results\n",
    "    plot_cross_validation_results(fold_results, average_accuracy, num_folds)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    # Plot misclassified samples\n",
    "    plot_misclassified_samples(dataset, all_labels, all_predictions)\n",
    "\n",
    "    # Generate classification report\n",
    "    generate_classification_report(all_labels, all_predictions)\n",
    "\n",
    "    # Calculate and save additional metrics\n",
    "    calculate_additional_metrics(all_train_loss_logs, all_val_loss_logs)\n",
    "\n",
    "def plot_cross_validation_results(fold_results, average_accuracy, num_folds):\n",
    "    plt.figure()\n",
    "    plt.bar(range(1, num_folds + 1), fold_results, tick_label=[f'Fold {i}' for i in range(1, num_folds + 1)])\n",
    "    plt.axhline(y=average_accuracy, color='r', linestyle='--', label=f'Average Accuracy: {average_accuracy:.4f}')\n",
    "    plt.title('Cross-Validation Accuracy')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(cross_validation_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_predictions):\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_misclassified_samples(dataset, all_labels, all_predictions):\n",
    "    misclassified_indices = [i for i, (label, pred) in enumerate(zip(all_labels, all_predictions)) if label != pred]\n",
    "    if misclassified_indices:\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        for i, idx in enumerate(misclassified_indices[:16]):  # Show up to 16 misclassified samples\n",
    "            image, label = dataset[idx]\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            plt.imshow(image.permute(1, 2, 0).numpy())\n",
    "            plt.title(f'True: {class_names[label]}, Pred: {class_names[all_predictions[idx]]}')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(misclassified_samples_path)\n",
    "        plt.close()\n",
    "\n",
    "def generate_classification_report(all_labels, all_predictions):\n",
    "    report = classification_report(all_labels, all_predictions, target_names=class_names)\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(report)\n",
    "    print(f\"Classification report saved to {report_path}\")\n",
    "\n",
    "def calculate_additional_metrics(all_train_loss_logs, all_val_loss_logs):\n",
    "    avg_train_loss_log = np.mean(all_train_loss_logs, axis=0)\n",
    "    avg_val_loss_log = np.mean(all_val_loss_logs, axis=0)\n",
    "\n",
    "    convergence_rate = (avg_train_loss_log[-1] - avg_train_loss_log[0]) / len(avg_train_loss_log)\n",
    "    overfitting_score = (avg_val_loss_log[-1] - avg_train_loss_log[-1]) / avg_val_loss_log[-1]\n",
    "    learning_plateau = np.mean(avg_val_loss_log[-5:]) - np.mean(avg_val_loss_log[:5])\n",
    "\n",
    "    with open(report_path, 'a') as f:\n",
    "        f.write(f\"\\nConvergence Rate: {convergence_rate:.4f}\\n\")\n",
    "        f.write(f\"Overfitting Score: {overfitting_score:.4f}\\n\")\n",
    "        f.write(f\"Learning Plateau: {learning_plateau:.4f}\\n\")\n",
    "\n",
    "# Run k-fold cross-validation\n",
    "k_fold_cross_validation(dataset)\n",
    "\n",
    "# Function to predict on a new image\n",
    "def predict_image(model, image_path, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = F.softmax(outputs, dim=1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return probabilities, predicted_class\n",
    "\n",
    "# Predict on a new image\n",
    "def predict_image(model, image_path, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = F.softmax(outputs, dim=1)[0]\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    \n",
    "    return probabilities, predicted_class\n",
    "\n",
    "# Predict on a new image\n",
    "new_image_probabilities, new_image_class = predict_image(model, new_image_path, transform)\n",
    "\n",
    "# Print and save predictions\n",
    "predictions = [f\"{class_names[i]}: {prob:.2f}\" for i, prob in enumerate(new_image_probabilities)]\n",
    "print(f\"Predictions for {new_image_path}:\")\n",
    "print(f\"Predicted class: {class_names[new_image_class]}\")\n",
    "print(\"Class probabilities:\")\n",
    "for pred in predictions:\n",
    "    print(pred)\n",
    "\n",
    "with open(predictions_output_file, 'w') as f:\n",
    "    f.write(f\"Predictions for {new_image_path}:\\n\")\n",
    "    f.write(f\"Predicted class: {class_names[new_image_class]}\\n\")\n",
    "    f.write(\"Class probabilities:\\n\")\n",
    "    for pred in predictions:\n",
    "        f.write(f\"{pred}\\n\")\n",
    "\n",
    "print(f\"Predictions saved to {predictions_output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
